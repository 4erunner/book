[[chapter_08_all_messagebus]]
== Going to Town on the Message Bus

In this chapter we'll start to make events more fundamental to the internal
structure of our application. We'll move from the current state in
<<all_in_on_messagebus_before_diagram>> where events are an optional
side-effect...


[[all_in_on_messagebus_before_diagram]]
.Before: Service Layer, with optional events, bus and handlers
image::images/all_in_on_messagebus_before_diagram.png[]
[role="image-source"]
----
[graphviz, all_in_on_messagebus_before_diagram]
digraph G {
rankdir=LR;
service [label="service-layer function"];
handlers [label="handler functions"];

flask -> service [label="request params\n(as primitives)"]
service -> model
model -> events -> messagebus -> handlers [style=dotted]

}
----

...to the situation in <<all_in_on_messagebus_after_diagram>> where
everything goes via the message bus, and our app has been transformed
fundamentally into a message-processor.

[[all_in_on_messagebus_after_diagram]]
.After: everything goes via the Message Bus
image::images/all_in_on_messagebus_after_diagram.png[]
[role="image-source"]
----
[graphviz, all_in_on_messagebus_after_diagram]
digraph G {
rankdir=LR;
flask [pos="0,0!"];
handler [label="handler function"];

flask -> event  [weight=10]
event -> messagebus  [weight=10]
messagebus -> handler  [weight=10]
handler -> model [weight=10]
model -> event [style=dotted, len=100]

}
----


=== A New Requirement Leads Us to Consider a New Architecture

Rich Hickey talks about "situated software", meaning software that runs for
extended periods of time, managing some real world process. Examples include
warehouse-management systems, logistics schedulers, and payroll systems.

This software is tricky to write because unexpected things happen all the time
in the real world of physical objects and unreliable humans. For example:

* during a stock-take, we discover that three SPRINGY-MATTRESSes have been
water damaged by a leaky roof.
* a consignment of RELIABLE-FORKs is missing the required documentation and is
held in customs for several weeks. Three RELIABLE-FORKs subsequently fail safety
testing, and are destroyed.
* a global shortage of sequins means we're unable to manufacture our next batch
of SPARKLY-BOOKCASE.

In all of these situations,  we learn about the need to change batch quantities
when they're already in the system.  Perhaps someone made a mistake on the number
in the manifest, or perhaps some sofas fell off a truck. Following a conversation with the
business,footnote:[https://en.wikipedia.org/wiki/Event_storming[Event storming]
is a common technique], we model the situation as in
<<batch_changed_events_flow_diagram>>:


[[batch_changed_events_flow_diagram]]
.batch quantity changed means deallocate and reallocate
image::images/batch_changed_events_flow_diagram.png[]
[role="image-source"]
----
[ditaa, batch_changed_events_flow_diagram]
+----------+    /----\      +------------+       +--------------------+
| Batch    |--> |RULE| -->  | Deallocate | ----> | AllocationRequired |
| Quantity |    \----/      +------------+-+     +--------------------+-+
| Changed  |                  | Deallocate | ----> | AllocationRequired |
+----------+                  +------------+-+     +--------------------+-+
                                | Deallocate | ----> | AllocationRequired |
                                +------------+       +--------------------+
----

An event we'll call _batch quantity changed_ should lead us to change the
quantity on the batch, yes, but also to apply a _business rule_: if the new
quantity drops to less than the total already allocated, we need to
_deallocate_  those orders from that batch. Then each one will require
a new allocation, which we can capture as an event called `AllocationRequired`.

Perhaps you're already anticipating that our internal messagebus and events can
help implement this requirement.  We could define a service called
`change_batch_quantity` that knows how to adjust batch quantities and also how
to _deallocate_ any excess order lines, and then each deallocation can emit an
`AllocationRequired` event which can be forwarded on to the existing `allocate`
service, in separate transactions.  Once again, our message bus helps us to
enforce the single responsibility principle, and it allows us to make choices about
transactions and data integrity.


==== Imagining an Architecture Change: Everything Will Be an Event Handler

But before we jump in, think about where we're headed.  There are two
kinds of flows through our system:

* API calls that are handled by a service-layer function,

* Internal events (which might be raised as a side-effect of a service-layer function)
  and their handlers (which in turn call service-layer functions).

Wouldn't it be easier if everything was an event handler?  If we rethink our API
calls as capturing events, then the service-layer functions can be event handlers
too, and we no longer need to make a distinction between internal and external
event handlers:

* `services.allocate()` we could imagine as being the handler for an
  `AllocationRequired` event, and it can emit `Allocated` events as its output.

* `services.add_batch()` could be the handler for a `BatchCreated`
  event.footnote:[If you've done a bit of reading around event-driven
    architectures, you may be thinking "some of these events sound more like
    commands!". Bear with us!  We're trying to introduce one concept at a time.
    In the <<chapter_09_commands,next chapter>> we'll introduce the distinction
    between command and events.]

Our new requirement will fit the same pattern:

* An event called `BatchQuantityChanged` can invoke a handler called
  `change_batch_quantity()`.

* And the new `AllocationRequired` events that it may raise can be passed on to
  `services.allocate()` too, so there is no conceptual difference between a
  brand-new allocation coming from the API, and a reallocation that's
  internally triggered by a deallocation.


All sound like a bit much?   Let's work towards it all gradually.  We'll
follow the
https://martinfowler.com/articles/preparatory-refactoring-example.html[Preparatory
Refactoring] workflow, AKA "make the change easy, then make the easy change":


* We'll start by refactoring our service layer into event handlers.  We can
  get used to the idea of events being the way we describe inputs to the
  system.  In particular, the existing `services.allocate()` function will
  become the handler for an event called `AllocationRequired`.

* Then we'll build an end-to-end test that puts `BatchQuantityChanged` events
  into the system, and looks for `Allocated` events coming out.

* And then our actual implementation will be conceptually very simple: a new
  handler for `BatchQuantityChanged` events, whose implementation will emit
  `AllocationRequired` events, which in turn will be handled by the exact same
  handler for allocations that the API uses.


=== Refactoring Service Functions to Message Handlers

We start by defining the two events that capture our current API inputs:
`AllocationRequired` and `BatchCreated`:

[[two_new_events]]
.BatchCreated and AllocationRequired events (src/allocation/events.py)
====
[source,python]
----
@dataclass
class BatchCreated(Event):
    ref: str
    sku: str
    qty: int
    eta: Optional[date] = None

...

@dataclass
class AllocationRequired(Event):
    orderid: str
    sku: str
    qty: int
----
====

Then we rename `services.py` to `handlers.py`, we add in with the existing
message handler for `send_out_of_stock_notification`, and most importantly,
we change all the handlers so that they have the same inputs:  an event
and a UoW:


[[services_to_handlers]]
.Handlers and services are the same thing (src/allocation/handlers.py)
====
[source,python]
----
def add_batch(
        event: events.BatchCreated, uow: unit_of_work.AbstractUnitOfWork
):
    with uow:
        product = uow.products.get(sku=event.sku)
        ...


def allocate(
        event: events.AllocationRequired, uow: unit_of_work.AbstractUnitOfWork
) -> str:
    line = OrderLine(event.orderid, event.sku, event.qty)
    ...


def send_out_of_stock_notification(
        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork,
):
    email.send(
        'stock@made.com',
        f'Out of stock for {event.sku}',
    )
----
====


The change might be clearer as a diff:

[[services_to_handlers_diff]]
.Changing from services to handlers (src/allocation/handlers.py)
====
[source,diff]
----
 def add_batch(
-        ref: str, sku: str, qty: int, eta: Optional[date],
-        uow: unit_of_work.AbstractUnitOfWork
+        event: events.BatchCreated, uow: unit_of_work.AbstractUnitOfWork
 ):
     with uow:
-        product = uow.products.get(sku=sku)
+        product = uow.products.get(sku=event.sku)
     ...


 def allocate(
-        orderid: str, sku: str, qty: int,
-        uow: unit_of_work.AbstractUnitOfWork
+        event: events.AllocationRequired, uow: unit_of_work.AbstractUnitOfWork
 ) -> str:
-    line = OrderLine(orderid, sku, qty)
+    line = OrderLine(event.orderid, event.sku, event.qty)
     ...

+
+def send_out_of_stock_notification(
+        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork,
+):
+    email.send(
     ...
----
====

Along the way, we've our service-layer's API, which was a scattering of
primitives, with some well-defined objects (see sidebar).

.From Domain Objects, via Primitive Obsession, to Events as an Interface
*******************************************************************************

Some of you may may remember the <<decouple_service_layer_from_domain>> section
from <<chapter_04_service_layer>>, in which we changed our service-layer API
from being in terms of domain objects, to primitives.  And now we're moving
back, but to different objects?  What gives?

In OO circles, people talk about _primitive obsession_ as an antipattern: avoid
primitives in public APIs, instead wrap them with custom value classes, they
would say.  In the Python world, a lot of people would be quite skeptical of
that as a rule of thumb. When mindlessly applied it's certainly a recipe for
unnecessary complexity.  So that's not what we're doing _per se_.

The move from domain objects to primitives bought us a nice bit of decoupling:
our client code was no longer coupled directly to the domain, so the service
layer could present an API that stay the same even if we decide to make changes
to our model, and vice-versa.

So have we gone backwards?  Well, our core domain model objects are still free to
vary, but instead we've coupled the external world to our Event classes instead.
They're part of the domain too, but the hope is that they vary less often, so
they're a sensible artifact to couple on.

And what have we bought ourselves?  Well, when invoking a use case in our application,
we no longer need to remember a particular combination of primitives, just a single
event class that represents the input to our application.  That's conceptually
quite nice.  On top of that, as we'll see in <<appendix_validation>>, those
events classes can be a nice place to do some input validation.

*******************************************************************************


==== The MessageBus Needs to Pass a UoW to Each Handler

Our event handlers now need a UoW.  We make a small modification
to the main `messagebus.handle()` function:


[[handle_takes_uow]]
.Handle takes a UoW (src/allocation/messagebus.py)
====
[source,python]
[role="non-head"]
----
def handle(event: events.Event, uow: unit_of_work.AbstractUnitOfWork):
    for handler in HANDLERS[type(event)]:
        handler(event, uow=uow)  #<1>
----
====

<1> The messagebus passes a UoW down to each handler


And to _unit_of_work.py_:


[[uow_passes_self_to_messagebus]]
.UoW passes self to message bus (src/allocation/unit_of_work.py)
====
[source,python]
----
class AbstractUnitOfWork(abc.ABC):
    ...

    def publish_events(self):
        for product in self.products.seen:
            while product.events:
                event = product.events.pop(0)
                messagebus.handle(event, uow=self)  #<1>
----
====

<1> The UoW passes itself to the messagebus. This pattern is called
    double-dispatch and it's a common trick for managing a circular dependency.


==== Our Tests Are All Written in Terms of Events Too:


[[handler_tests]]
.Handler Tests use Events (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
class TestAddBatch:

    @staticmethod
    def test_for_new_product():
        uow = FakeUnitOfWork()
        messagebus.handle(events.BatchCreated("b1", "CRUNCHY-ARMCHAIR", 100, None), uow)
        assert uow.products.get("CRUNCHY-ARMCHAIR") is not None
        assert uow.committed

...


class TestAllocate:

    @staticmethod
    def test_returns_allocation():
        uow = FakeUnitOfWork()
        messagebus.handle(events.BatchCreated("b1", "COMPLICATED-LAMP", 100, None), uow)
        result = messagebus.handle(events.AllocationRequired("o1", "COMPLICATED-LAMP", 10), uow)
        assert result == "b1"
----
====

// TODO: (DS) why staticmethod?


==== A Temporary Ugly Hack: The Messagebus Has to Return Results

Our API and our service layer currently want to know the allocated batch ref
when they invoke our `allocate()` handler.  This means we need to put in
a temporary hack on our messagebus to let it return events.

[[hack_messagebus_results]]
.Messagebus returns results (src/allocation/messagebus.py)
====
[source,diff]
----
 def handle(event: events.Event, uow: unit_of_work.AbstractUnitOfWork):
+    results = []
     for handler in HANDLERS[type(event)]:
-        handler(event, uow=uow)
+        r = handler(event, uow=uow)
+        results.append(r)
+    return results
----
====


It's because we're mixing the read and write responsibilities in our system.
We'll come back to fix this wart in <<chapter_09_cqrs>>.

==== Modifying Our API to Do Events

[[flask_uses_messagebus]]
.Flask changing to messagebus as a diff (src/allocation/flask_app.py)
====
[source,diff]
----
 @app.route("/allocate", methods=['POST'])
 def allocate_endpoint():
     try:
-        batchref = services.allocate(
-            request.json['orderid'],  #<1>
-            request.json['sku'],
-            request.json['qty'],
-            unit_of_work.SqlAlchemyUnitOfWork(),
+        event = events.AllocationRequired(  #<2>
+            request.json['orderid'], request.json['sku'], request.json['qty'],
         )
+        results = messagebus.handle(event, unit_of_work.SqlAlchemyUnitOfWork())  #<3>
+        batchref = results.pop()
     except exceptions.InvalidSku as e:
----
====

<1> Instead of calling the service layer with a bunch of primitives extracted
    from the request JSON...

<2> We instantiate an event

<3> And pass it to the messagebus.



And we should be back to a fully functional application, but one that's now
fully event-driven.

* What used to be service-layer functions are now event handlers...

* ...As are the functions we invoke for handling internal events raise by
  our domain model

* We use events as our datastructure for capturing inputs to the system,
  as well as for handoff of internal work packages.

* The entire app is now best described as a message processor (or event processor
  if you prefer.  We'll talk about the distinction in the
  <<chapter_09_commands, next chapter>>.



=== Implementing Our New Requirement

We're done with our refactoring phase. Let's see if we really have "made the
change easy".  Let's implement our new requirement: we'll receive as our
inputs some new `BatchQuantityChanged` events, pass them to a handler, which in
turn might emit some `AllocationRequired` events, and those in turn will go
back to our existing handler for allocation, to be re-allocated.


[[reallocation_sequence_diagram]]
.Sequence diagram for reallocation flow
image::images/reallocation_sequence_diagram.png[]
[role="image-source"]
----
[plantuml, reallocation_sequence_diagram, config=plantuml.cfg]
@startuml
API -> MessageBus : BatchQuantityChanged event

group BatchQuantityChanged Handler + Unit of Work 1
    MessageBus -> Domain_Model : change batch quantity
    Domain_Model -> MessageBus : emit AllocationRequired event(s)
end


group AllocationRequired Handler + Unit of Work 2 (or more)
    MessageBus -> Domain_Model : allocate
end

@enduml
----


////
TODO (ej)  There is a minor but important technical point here, I think, that
could be a source of confusion.  The UOW and session commit are not exactly
synonymous as the events are not actually emitted until after the UOW "ends".
Otherwise you could end up with a race or skew on the persisted state. (Or
would that be prevented by re-using the same uow+session instance in the event
handlers?)

I am unsure how to present that information without adding a lot of
detail to the sequence diagram.
////


==== Our New Event

The event that tells us a batch quantity has changed is very simple, it just
needs a batch reference and a new quantity:


[[batch_quantity_changed_event]]
.New event (src/allocation/events.py)
====
[source,python]
----
@dataclass
class BatchQuantityChanged(Event):
    ref: str
    qty: int
----
====


=== Test-Driving a New Handler

Following the lessons learned in <<chapter_03_service_layer>>,
we can operate in "high gear," and write our unit tests at the highest
possible level of abstraction, in terms of events. Here's what they might
look like:


[[test_change_batch_quantity_handler]]
.Handler tests for change_batch_quantity (tests/unit/test_handlers.py)
====
[source,python]
----
class TestChangeBatchQuantity:

    @staticmethod
    def test_changes_available_quantity():
        uow = FakeUnitOfWork()
        messagebus.handle(events.BatchCreated("batch1", "ADORABLE-SETTEE", 100, None), uow)
        [batch] = uow.products.get(sku="ADORABLE-SETTEE").batches
        assert batch.available_quantity == 100  #<1>

        messagebus.handle(events.BatchQuantityChanged("batch1", 50), uow)

        assert batch.available_quantity == 50  #<1>


    @staticmethod
    def test_reallocates_if_necessary():
        uow = FakeUnitOfWork()
        messagebus.handle(events.BatchCreated("batch1", "INDIFFERENT-TABLE", 50, None), uow)
        messagebus.handle(events.BatchCreated("batch2", "INDIFFERENT-TABLE", 50, date.today()), uow)
        messagebus.handle(events.AllocationRequired("order1", "INDIFFERENT-TABLE", 20), uow)
        messagebus.handle(events.AllocationRequired("order2", "INDIFFERENT-TABLE", 20), uow)
        [batch1, batch2] = uow.products.get(sku="INDIFFERENT-TABLE").batches
        assert batch1.available_quantity == 10

        messagebus.handle(events.BatchQuantityChanged("batch1", 25), uow)

        # order1 or order2 will be deallocated, so we"ll have 25 - 20 * 1
        assert batch1.available_quantity == 5  #<2>
        # and 20 will be reallocated to the next batch
        assert batch2.available_quantity == 30  #<2>
----
====

<1> The simple case would be trivially easy to implement, we just
    modify a quantity.

<2> But if we try and change the quantity so that there's less than
    has been allocated, we'll need to deallocate at least one order,
    and we expect to reallocated it to a new batch





==== Implementation

[[change_quantity_handler]]
.Handler delegates to model layer (src/allocation/handlers.py)
====
[source,python]
----
def change_batch_quantity(
        event: events.BatchQuantityChanged, uow: unit_of_work.AbstractUnitOfWork
):
    with uow:
        product = uow.products.get_by_batchref(batchref=event.ref)
        product.change_batch_quantity(ref=event.ref, qty=event.qty)
        uow.commit()
----
====
// TODO (DS): Indentation looks off


We realize we'll need a new query type on our repository:

[[get_by_batchref]]
.A new query type on our repository (src/allocation/repository.py)
====
[source,python]
----
class AbstractRepository(abc.ABC):
    ...

    def get(self, sku) -> model.Product:
        ...

    def get_by_batchref(self, batchref) -> model.Product:
        product = self._get_by_batchref(batchref)
        if product:
            self.seen.add(product)
        return product

    @abc.abstractmethod
    def _add(self, product: model.Product):
        raise NotImplementedError

    @abc.abstractmethod
    def _get(self, sku) -> model.Product:
        raise NotImplementedError

    @abc.abstractmethod
    def _get_by_batchref(self, batchref) -> model.Product:
        raise NotImplementedError


    ...

    def _get(self, sku):
        return self.session.query(model.Product).filter_by(sku=sku).first()

    def _get_by_batchref(self, batchref):
        return self.session.query(model.Product).join(model.Batch).filter(
            orm.batches.c.reference == batchref,
        ).first()

----
====

And on our `FakeRepository` too:

[[fakerepo_get_by_batchref]]
.Updating the fake repo too (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
class FakeRepository(repository.AbstractRepository):
    ...

    def _get(self, sku):
        return next((p for p in self._products if p.sku == sku), None)

    def _get_by_batchref(self, batchref):
        return next((
            p for p in self._products for b in p.batches
            if b.reference == batchref
        ), None)
----
====


// TODO: discuss finder methods on repository.


==== A New Method on the Domain Model

We add the new method to the model, which does the quantity change and
deallocation(s) inline, and publishes a new event.  We also modify the existing
allocate function to publish an event.


[[change_batch_model_layer]]
.Our model evolves to capture the new requirement (src/allocation/model.py)
====
[source,python]
----
class Product:
    ...

    def change_batch_quantity(self, ref: str, qty: int):
        batch = next(b for b in self.batches if b.reference == ref)
        batch._purchased_quantity = qty
        while batch.available_quantity < 0:
            line = batch.deallocate_one()
            self.events.append(
                events.AllocationRequired(line.orderid, line.sku, line.qty)
            )
...

class Batch:
    ...

    def deallocate_one(self) -> OrderLine:
        return self._allocations.pop()
----
====

We wire up our new handler:


[[full_messagebus]]
.The messagebus grows (src/allocation/messagebus.py)
====
[source,python]
----
HANDLERS = {
    events.BatchCreated: [handlers.add_batch],
    events.BatchQuantityChanged: [handlers.change_batch_quantity],
    events.AllocationRequired: [handlers.allocate],
    events.OutOfStock: [handlers.send_out_of_stock_notification],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====


And our new requirement is fully implemented.



.Unit Testing Event Handlers in Isolation with a Fake Message Bus
*******************************************************************************

Our main test for the reallocation workflow
(<<test_change_batch_quantity_handler>>) is "edge-to-edge".  It uses
the real messagebus, and it tests the whole flow, where the `BatchQuantityChanged`,
event handler triggers deallocation, emits new `AllocationRequired` events, which in
turn are handled by their own handlers.  One test covers a chain of multiple
events and handlers.

Depending on the complexity of your chains of events, you may decide that you
want to test some handlers in isolation from one another.  You can do this
using a "fake" messagebus.

In our case, we actually intervene by modifying the `publish_events()` method
on `FakeUnitOfWork`, and decouple it from the real messagebus, instead making
it record what events it sees:


[[fake_messagebus]]
.Fake MessageBus implemented in UoW (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
class FakeUnitOfWorkWithFakeMessageBus(FakeUnitOfWork):

    def __init__(self):
        super().__init__()
        self.events_published = []  # type: List[events.Event]

    def publish_events(self):
        for product in self.products.seen:
            while product.events:
                self.events_published.append(product.events.pop(0))
----
====

Now when we invoke `messagebus.handle()` using the `FakeUnitOfWorkWithFakeMessageBus`,
it only does one event/handler at a time.  So we can write a more isolated unit
test: instead of checking all the side effects, we just check that
`BatchQuantityChanged` leads to `AllocationRequired` if the quantity drops
below the total already allocated:


[[test_handler_in_isolation]]
.Testing reallocation in isolation (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
def test_reallocates_if_necessary_isolated():
    uow = FakeUnitOfWorkWithFakeMessageBus()

    # test setup as before
    messagebus.handle(events.BatchCreated("batch1", "INDIFFERENT-TABLE", 50, None), uow)
    messagebus.handle(events.BatchCreated("batch2", "INDIFFERENT-TABLE", 50, date.today()), uow)
    messagebus.handle(events.AllocationRequired("order1", "INDIFFERENT-TABLE", 20), uow)
    messagebus.handle(events.AllocationRequired("order2", "INDIFFERENT-TABLE", 20), uow)
    [batch1, batch2] = uow.products.get(sku="INDIFFERENT-TABLE").batches
    assert batch1.available_quantity == 10

    messagebus.handle(events.BatchQuantityChanged("batch1", 25), uow)

    # assert on new events emitted rather than downstream side-effects
    [reallocation_event] = uow.events_published
    assert isinstance(reallocation_event, events.AllocationRequired)
    assert reallocation_event.orderid in {'order1', 'order2'}
    assert reallocation_event.sku == 'INDIFFERENT-TABLE'
----
====

Whether you want to do this or not depends on the complexity of your chain of
events.  We'd say, start out with edge-to-edge testing, and only resort to
this if necessary.


If you do decide you want to get into isolating the testing for your handlers,
you might be better of implementing an ABC for your messagebus:


[[abc_for_fake_messagebus]]
.An Abstract MessageBus and its real and fake versions
====
[source,python]
[role="skip"]
----
class AbstractMessageBus:
    HANDLERS: Dict[Type[events.Event], List[Callable]]

    def handle(self, event: events.Event):
        for handler in self.HANDLERS[type(event)]:
            handler(event)


class MessageBus(AbstractMessageBus):
    HANDLERS = {
        events.OutOfStock: [send_out_of_stock_notification],

    }


class FakeMessageBus(messagebus.AbstractMessageBus):
    def __init__(self):
        self.events_published = []  # type: List[events.Event]
        self.handlers = {
            events.OutOfStock: [lambda e: self.events_published.append(e)]
        }
----
====

We use a class-based messagebus in <<chapter_12_dependency_injection>>,
if you need more inspiration.  The "simple" implementation in this
chapter essentially uses the `messagebus.py` module itself to implement
Singleton Pattern.


*******************************************************************************





=== What Have We Achieved?

* Events are simple dataclasses that define the data structures for inputs,
  and internal messages within our system.  This is quite powerful from a DDD
  standpoint, since events often translate really well into business language
  (in fact an entire practice know as "Event Storming" has evolved around it).

* Handlers are the way we react to events.   They can call down to our
  model, or they can call out to external services.  We can define multiple
  handlers for a single event if we want to.  Handlers can also raise other
  events.  This allows us to be very granular about what a handler does,
  and really stick to the SRP.


=== Why Have We Achieved?

Our ongoing objective with these architectural patterns is to try and have
the complexity of our application grow more slowly than its size.  Here
we've added quite a complicated use case (change quantity, deallocate, start
new transaction, reallocate, publish external notification), but architecturally,
there's been no cost in terms of complexity.  We've added new events, new handlers,
and a new external adapter (for email), all of which are existing categories
of _things_ in our architecture that we understand and know how to reason about,
and that are easy to explain to newcomers.  Our moving parts each have one job,
they're connected to each other in well-defined ways, and there are no unexpected
side-effects.

Now, you may be wondering, where are those `BatchQuantityChanged` events actually
going to come from?  The answer is coming up in a couple of chapters' time.  But
first, let's talk about <<chapter_09_commands,Events versus Commands>>.


[[chapter_08_all_messagebus_tradeoffs]]
[options="header"]
.Whole app is a Message Bus: The Trade-Offs
|===
|Pros|Cons
a|
* handlers and services are the same thing, so that's simpler
* we have a nice datastructure for inputs to the system

a|
* messagebus is still a slightly unpredictable way of doing things from
  a web pov.  don't know in advance when things are going to end

* we've gone from domain objects in service layer calls, to primitives,
  and now to domain events, which feels flip-floppey.

* duplication / maintenance cost of having model objects _and_ events
  now.  adding a field to one usually means adding a field to at least
  on of the others
|===
