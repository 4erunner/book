[[chapter_03]]
== Our first use case:  Flask API and service layer.

Like any good agile team, we're hustling to try and get an MVP out and
in front of the users to start gathering feedback.  We have the core
of our domain model and the domain service we need to allocate orders,
and we have the Repository interface for permanent storage.

Let's try and plug all the moving parts together as quickly as we
can, and then refactor towards a cleaner architecture.


=== A first end-to-end (E2E) test

No-one is interested in getting into a long terminology debate about what
counts as an E2E test vs a functional test vs an acceptance test vs an
integration test vs unit tests.  Different projects need different combinations
of tests, and we've seen perfectly successful projects just split things into
"fast tests" and "slow tests".

For now we want to write one or maybe two tests that are going to exercise
a "real" API endpoint (using HTTP) and talk to a real database. Let's call
them end-to-end tests because it's one of the most self-explanatory names.

<<first_api_test>> shows a first cut:




[[first_api_test]]
.A first API test (test_api.py)
====
[source,python]
----
def random_ref(prefix):
    return prefix + '-' + uuid.uuid4().hex[:10]

@pytest.mark.usefixtures('restart_api')
def test_api_for_allocation(add_stock, postgres_session):
    sku1, sku2 = random_ref('s1'), random_ref('s2')
    batch1, batch2, batch3 = random_ref('b1'), random_ref('b2'), random_ref('b3')
    add_stock([
        (batch1, sku1, 100, None),
        (batch2, sku2, 100, '2011-01-01'),
        (batch3, sku2, 100, '2011-01-02'),
    ])
    data = {
        'order_reference': random_ref('o'),
        'lines': {sku1: 3, sku2: 12},
    }
    url = config.get_api_url()
    r = requests.post(f'{url}/allocate', json=data)
    assert r.status_code == 201
    rows = list(postgres_session.execute(
        'SELECT l.sku, b.reference FROM allocations'
        ' JOIN order_lines as l ON orderline_id=l.id'
        ' JOIN batches as b ON batch_id=b.id',
    ))
    assert (sku1, batch1) in rows
    assert (sku2, batch2) in rows
----
====

Everyone solves these problems in different ways, but you're going
to need some way of spinning up Flask, possibly in a container, and
also talking to a postgres database.  If you want to see how we did
it, check out <<appendix_project_structure>>.


=== The naive implementation

Implementing things in the most obvious way, you might get something like this:


[[first_cut_flask_app]]
.First cut flask app (flask_app.py)
====
[source,python]
[role="non-head"]
----
orm.start_mappers()
get_session = sessionmaker(bind=create_engine(config.get_postgres_uri()))


app = Flask(__name__)

@app.route("/allocate", methods=['POST'])
def allocate_endpoint():
    try:
        session = get_session()
        batches = repository.BatchRepository(session).list()
        ref = request.json['order_reference']
        lines = [
            model.OrderLine(ref, sku, qty)
            for sku, qty in request.json['lines'].items()
        ]
        model.allocate(lines, batches)

        session.commit()
        return 'OK', 201
    finally:
        session.close()
----
====


So far so good.  No need for too much more of your "architecture astronaut"
nonsense, Bob and Harry, you may be thinking.  But you probably _are_ 
thinking that the end-to-end test is pretty ugly so far.


=== Error conditions that require database checks

Let's add a bit of error-handling shall we?  What if we receive an order
that's already been allocated?  To do that, we need to check the database
for existing allocations for that order, something that's not really the
remit of the domain layer.

TODO: update from this point on for batches.

So we could dive in and start writing something like <<test_already_allocated>>:

[[test_already_allocated]]
.We could test at the e2e layer but...  (test_api.py)
====
[source,python]
----
@pytest.mark.usefixtures('restart_api')
def test_allocation_already_exists_error_in_json_message(add_stock):
    sku1, oref, batchref = random_ref('s1'), random_ref('o'), random_ref('b')
    add_stock([
        (batchref, sku1, 100, None),
    ])
    data = {'order_reference': oref, 'lines': {sku1: 3}}
    url = config.get_api_url()
    r = requests.post(f'{url}/allocate', json=data)
    assert r.status_code == 201
    r = requests.post(f'{url}/allocate', json=data)
    assert r.status_code == 400
    assert r.text == f'Order {oref} already allocated'

----
====

But that's not really enough.  We should probably also explicitly check that
stock quantities are not decremented.  Soon our E2E tests are going to become
unwieldy, and we'll end up with an inverted test pyramid.


=== Introducing a service layer, and using FakeRepository to unit test it

let's move the orchestration stuff into a _services.py_ and use some
fakerepositories to test it:


[[first_services_test]]
.Unit testing with fakes at the services layer (test_services.py)
====
[source,python]
----
def test_error_if_allocation_already_exists():
    line = model.OrderLine('o1', 'sku1', 10)
    batch = model.Batch('b1', 'sku1', 100, eta=None)
    batch.allocate(line)
    repo = FakeRepository([batch])

    with pytest.raises(services.OrderAlreadyAllocated) as ex:
        services.allocate([line], repo)

    assert 'Order o1 already allocated' in str(ex)

----
====



[[fake_repo]]
.Our fake repository (test_services.py)
====
[source,python]
----
class FakeRepository(set):

    def get(self, reference):
        return next(x for x in self if x.reference == reference)

    def list(self):
        return list(self)
----
====


But now we can migrate some of the other E2E tests too, like the one
that checks we actually save to the repo, <<second_test>>:

TODO: discuss moving _all_ the domain unit tests to the services layer too


[[second_servicetest]]
.A second test at the service layer (test_services.py)
====
[source,python]
----
def test_actually_allocates():
    line = model.OrderLine('o1', 'sku1', 10)
    batch = model.Batch('b1', 'sku1', 100, eta=None)
    repo = FakeRepository([batch])

    services.allocate([line], repo)

    assert batch.available_quantity == 90
----
====

And the test that we decrement quantities too.

We'll get to a service function that looks something like <<service_function>>:

[[service_function]]
.Basic allocation service (services.py)
====
[source,python]
----
class OrderAlreadyAllocated(Exception):
    pass


def allocate(lines: List[OrderLine], repo: BatchRepository) -> None:
    batches = repo.list()

    existing_allocations = set(a for batch in batches for a in batch._allocations)
    if any(l in existing_allocations for l in lines):  #<1>
        raise OrderAlreadyAllocated(f'Order {lines[0].orderid} already allocated')

    model.allocate(lines, batches)  #<2>
----
====

Typical service-layer functions have similar steps:

<1> We make some checks or assertions about the request against
    the current state of the world

<2> We may instantiate a domain object, and/or call a domain service

TODO: no step 3, add a new object to a repo, sadly


And now our flask app is looking reasonably sane, <<flask_app_using_service_layer>>:


[[flask_app_using_service_layer]]
.Flask app delegating to service layer (flask_app.py)
====
[source,python]
----
@app.route("/allocate", methods=['POST'])
def allocate_endpoint():
    try:
        session = get_session()  #<1>
        repo = repository.BatchRepository(session)  #<1>
        ref = request.json['order_reference']  #<2>
        lines = [
            model.OrderLine(ref, sku, qty)
            for sku, qty in request.json['lines'].items()  #<2>
        ]
        try:
            services.allocate(lines, repo)
            session.commit()
            return 'OK', 201  #<3>
        except services.OrderAlreadyAllocated as e:
            return str(e), 400  #<3>

    finally:
        session.close()
----
====

We see that the responsibilities of the flask app are much more minimal, and
more focused on just the web stuff:

<1> We instantiate a database session and some repository objects.
<2> We extract the user's commands from the web request and pass them
    to a domain service.
<3> And we return some responses and status codes

The responsibilities of the flask app are just standard web stuff: per-request
session management, parsing information out of POST parameters, response status
codes and JSON.  All the orchestration logic is in the use case / service layer,
and the domain logic stays in the domain.



=== How is our test pyramid looking?

[[test_pyramid]]
.Counting different types of test
====
[source,sh]
[role="skip"]
----
ðŸ‘‰  grep -c test_ test_*.py
test_batches.py:8
test_allocate.py:6
test_services.py:2
test_orm.py:6
test_repository.py:2
test_api.py:2
----
====

//TODO: test this too?

Not bad!  16 unit tests, 8 integration tests, and just 2 end-to-end tests.


But there's still some things we're not happy with.  Passing that repository
around feels awkward, and the service/orchestration layer should probably
be in charge of the commit.  We'll introduce a nice pattern to deal with
that in the next chapter.


TODO: mention commit, still not tested

TODO: mention the word "use case"

TODO: integrate folder structure stuff at some point.

