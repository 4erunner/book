[[chapter_11_cqrs]]
== Command-Query Responsibility Separation (CQRS)

In this chapter we're going to take a fairly uncontroversial insight--the
fact that reads (commands) and writes (queries) are different, and so they
should be treated differently--and we're going to push that insight out way
beyond the bounds of sanity and into fullblown boomtown architecture-astronaut
crazyland.  We may provide a few justifications along the way of when you
might or might not want to do it, bla-bla-bla-performance and so forth, but,
honestly, it's just because we want to see the world burn.  In a decoupled way.

NOTE: Chapter under construction.  More sober and coherent treatment of the subject
    may be found at
    https://io.made.com/blog/2017-09-13-commands-and-queries-handlers-and-views.html

// TODO: replace with cosmicpython.com url

So strap in, and see if you can spot the moment where the madness descends.
Because you need to be on the lookout for that moment in your own life.


=== Always Redirect After a POST

If you've been doing web development, you're probably familiar with the convention
to return a 302-redirect from a POST request.  That's an example of
Command-Query Separation (CQS), which is at the sane end of the CQRS spectrum.

For an API, redirects don't apply, but the principle of POST-Redirect-GET
is still a good one, and we're currently breaking that rule, because our
`allocate` endpoint currently returns the batch ID.  Let's change it
to return a simple OK message, and instead provide a new read-only
endpoint to retrieve allocation state:


[[api_test_does_get_after_post]]
.API test does a GET after the POST (tests/e2e/test_api.py)
====
[source,python]
----
@pytest.mark.usefixtures('postgres_db')
@pytest.mark.usefixtures('restart_api')
def test_happy_path_returns_202_and_batch_is_allocated():
    orderid = random_orderid()
    sku, othersku = random_sku(), random_sku('other')
    batch1, batch2, batch3 = random_batchref(1), random_batchref(2), random_batchref(3)
    api_client.post_to_add_batch(batch1, sku, 100, '2011-01-02')
    api_client.post_to_add_batch(batch2, sku, 100, '2011-01-01')
    api_client.post_to_add_batch(batch3, othersku, 100, None)

    r = api_client.post_to_allocate(orderid, sku, qty=3)
    assert r.status_code == 202

    r = api_client.get_allocation(orderid)
    assert r.ok
    assert r.json() == [
        {'sku': sku, 'batchref': batch2},
    ]


@pytest.mark.usefixtures('postgres_db')
@pytest.mark.usefixtures('restart_api')
def test_unhappy_path_returns_400_and_error_message():
    unknown_sku, orderid = random_sku(), random_orderid()
    r = api_client.post_to_allocate(
        orderid, unknown_sku, qty=20, expect_success=False,
    )
    assert r.status_code == 400
    assert r.json()['message'] == f'Invalid sku {unknown_sku}'

    r = api_client.get_allocation(orderid)
    assert r.status_code == 404
----
====


OK what might the flask app look like?


[[flask_app_calls_view]]
.Endpoint for viewing allocations (src/allocation/flask_app.py)
====
[source,python]
----
from allocation import commands, exceptions, messagebus, orm, unit_of_work, views
...

@app.route("/allocations/<orderid>", methods=['GET'])
def allocations_view_endpoint(orderid):
    uow = unit_of_work.SqlAlchemyUnitOfWork()
    result = views.allocations(orderid, uow)  #<1>
    if not result:
        return 'not found', 404
    return jsonify(result), 200
----
====

<1> All right, a _views.py_, fair enough, we can keep read-only stuff in there,
    and it'll be a real views.py, not like Django's, something that knows how
    to build read-only views of our data...


=== Hold on to Your Lunch Folks.

...so we can probably just add a list method to our existing repository
obj-...


[[views_dot_py]]
.Views do... raw sql??? (src/allocation/views.py)
====
[source,python]
[role="non-head"]
----
from allocation import unit_of_work

def allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):
    with uow:
        results = list(uow.session.execute(
            'SELECT ol.sku, b.reference'
            ' FROM allocations AS a'
            ' JOIN batches AS b ON a.batch_id = b.id'
            ' JOIN order_lines AS ol ON a.orderline_id = ol.id'
            ' WHERE ol.orderid = :orderid',
            dict(orderid=orderid)
        ))
    return [{'sku': sku, 'batchref': batchref} for sku, batchref in results]
----
====

WHAT THE ACTUAL F?  ARE YOU GUYS TRIPPING F-ING BALLS?

Yes.  Yes we are.  Obviously don't do this.  Unless you have Reasons (TM). Let's come
back to that and assume you don't.  You probably don't.  Go ahead and do
something sane instead:


[[view_using_repo]]
.A simple view that uses the repository (src/allocation/views.py)
====
[source,python]
[role="skip"]
----
from allocation import unit_of_work

def allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):
    with uow:
        products = uow.products.for_order(orderid=orderid)
        batches = [b for p in products for b in p.batches]
        return [
            {'sku': b.sku, 'batchref': b.reference}
            for b in batches
            if orderid in b.orderids
        ]
----
====

We're sure you can figure out how to write a query called `.for_order()`
on your repository that can find all the products for an order.


Note that splitting out a _views.py_ module and enforcing a clear
distinction between reads and writes in your application is still
probably a good idea.  We apply command-query separation, and it's easy to see
which code modifies state (the event handlers) and which code just retrieves
read-only state (the views).

TIP: Split out your read-only views from your state-modifying
    command and event handlers.


=== Why on Earth Would You Write Raw SQL in Your Views?

OK Bob and Harry, let's get back to that SQL monstrosity though.  Why
on earth would you show us that?  Don't think we're about to forget, the
sheer horror has been permanently burned into our memories.  Why on
earth would you want to do that? _Ever?_

Broadly speaking there are two reasons:

1. Performance.
2. Keeping your Domain Model free of Spurious Concerns.


==== SELECT N+1

The so-called
https://secure.phabricator.com/book/phabcontrib/article/n_plus_one/[SELECT N+1]
problem is a common performance problem with ORMs: when retrieving a list of
objects, your ORM will often perform an initial query to, say, get all the IDs
of the objects it needs, and then issue individual queries for each object to
retrieve their attributes.  This is especially likely if there are any foreign
key relationships on your objects.

//TODO: set echo=True and show SQL query logs in our own app?


==== General Database Read Performance

Beyond `SELECT N+1`, you may have other reasons that you want to decouple the
way you persist state changes from the way that you retrieve current state.
A set of fully normalized relational tables is a good way to make sure that
write operations never cause data corruption.  But retrieving data using lots
of JOINs can be slow.  It's common in such cases to add some denormalized views
(we'll see an example of that later), build read replicas, or even add caching
layers.


==== Your Domain Model is not Optimized for Read Operations

Now here's the chinstrokey-architect justification.  As we've said before,
a Domain Model is not a data model--we're trying to capture the way the
business works: workflow, rules around state changes, messages exchanged;
concerns about how the system reacts to external events and user input.
_Most of this stuff is totally irrelevant for read-only operations_.

Making a facile point, your domain classes will have a number of methods for
modifying state, and you won't need any of them for read-only operations.
Now that is very, very, very far away from a justification for using raw
SQL instead of reusing our domain objects for queries, but you can at
least see how the two are conceptually different.

As the complexity of your domain model grows though, you may find yourself
making more and more choices about how to structure that model, which make
it more and more awkward to use for read operations.

Even in our simple example, we've chosen to use `Product` as our aggregate,
but for our "show me the allocations for this order id" endpoint, going
via Product isn't really the most obvious way of doing things.  In
<<view_using_repo>> we retrieve all the products for the skus in the order,
then we find all the batches for those products, and _then_ we iterate (slowly,
in Python) through all of them finding the ones that have allocations for that
order id?  It's clunky.  And we didn't mention it at the time, but we had to
add a new `@property` to the domain model to be able to get the order ids
allocated to a batch:

[[orderids_on_batch]]
.An argubably-uneccessary property on our model (src/allocation/model.py)
====
[source,python]
[role="skip"]
----
class Batch:
    ...

    @property
    def orderids(self):
        return {l.orderid for l in self._allocations}
----
====


=== Using the ORM is Probably Simpler.  Probably.

You may be thinking, OK, if our repository is clunky, then I can just use my
ORM.  That's what it's for!

[[view_using_orm]]
.A simple view that uses the ORM (src/allocation/views.py)
====
[source,python]
[role="skip"]
----
from allocation import unit_of_work, model

def allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):
    with uow:
        batches = uow.session.query(model.Batch).join(
            model.OrderLine, model.Batch._allocations
        ).filter(
            model.OrderLine.orderid == orderid
        )
        return [
            {'sku': b.sku, 'batchref': b.batchref}
            for b in batches
        ]
----
====

But is that _actually_ any easier to write or understand than the raw SQL
version from <<views_dot_py>>?  It may not look too bad up there, but we
can tell you it took several attempts, and plenty of digging through the
SQLAlchemy docs.  SQL is just SQL.


=== Testing CQRS Views

Let's talk about testing.  Whichever of the approaches you decide to go for,
the most obvious kind of test to write is an integration test, one that goes
to a real database.

This test would work for any of the approaches we've shown so far:


[[integration_testing_views]]
.An integration test for a view (tests/integration/test_views.py)
====
[source,python]
----
from datetime import date
from allocation import commands, unit_of_work, messagebus, views


def test_allocations_view(sqlite_session_factory):
    uow = unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory)
    messagebus.handle(commands.CreateBatch('sku1batch', 'sku1', 50, None), uow)
    messagebus.handle(commands.CreateBatch('sku2batch', 'sku2', 50, date.today()), uow)
    messagebus.handle(commands.Allocate('order1', 'sku1', 20), uow)
    messagebus.handle(commands.Allocate('order1', 'sku2', 20), uow)
    # add a spurious batch and order to make sure we're getting the right ones
    messagebus.handle(commands.CreateBatch('sku1batch-later', 'sku1', 50, date.today()), uow)
    messagebus.handle(commands.Allocate('otherorder', 'sku1', 30), uow)
    messagebus.handle(commands.Allocate('otherorder', 'sku2', 10), uow)

    assert views.allocations('order1', uow) == [
        {'sku': 'sku1', 'batchref': 'sku1batch'},
        {'sku': 'sku2', 'batchref': 'sku2batch'},
    ]
----
====

Before you dismiss the need to use integration tests as just another
anti-feather in the anti-cap of this total anti-pattern, it's worth thinking
through the alternatives.

- If you're going via the `Products` repository, then you'll need integration
    tests for the `.for_order()` helper method

- If you're going via the ORM, you'll still need integration tests

- And if you decide to build a read-only `BatchRepository`, ignoring
  the purists that tell you you're not allowed to have a Repository for
  a non-Aggregate model class, call it `BatchDAL` if you want, in any case,
  you'll still need integration tests for _that_.

So the choice is about whether or not you want a layer of abstraction between
your permanent storage and the logic of your read-only views.

* If the views are relatively simple (all the logic in our case is in filtering
  down to the right batch references), then adding another layer doesn't seem
  worth it.

* If your views do more complex calculations, or need to invoke some business rules
  to decide what to display... If, in short, you find yourself writing a lot of
  integration tests for a single view, then it may be worth building that
  intermediary layer, so that you can test the SQL and the display/calculation/view
  logic separately


// TODO: some example code showing a DAL layer in front of some read-only view
// code with more complex business logic.


=== Doubling Down on the Madness.

Have we convinced you that our raw SQL version isn't so crazy as it first
seemed?  Perhaps we were exaggerating the craziness for effect?

Just you wait.

So. Crazy or not, that hardcoded SQL query is pretty ugly right?  What if we
made it nicer by keeping a totally separate, denormalized datastore for our
view model?

Horrifying, right?  Wait 'til we tell you we're not even going to use Postgres
views, or triggers, or anything known and reliable and boring like that, to
keep it up to date.  We're going to use our amazing event-driven architecture!
That's right!  May as well join the cult and start drinking folks, the ship is
made of cardboard and the captains are crazy and there's nothing you can do to
stop them.


[[much_nicer_query]]
.A much nicer query (src/allocation/views.py)
====
[source,python]
----
def allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):
    with uow:
        results = list(uow.session.execute(
            'SELECT sku, batchref FROM allocations_view WHERE orderid = :orderid',
            dict(orderid=orderid)
        ))
        ...
----
====

Here's our table.  Hee hee hee, no foreign keys, just strings, YOLO.

[[new_table]]
.A very simple table (src/allocation/orm.py)
====
[source,python]
----
allocations_view = Table(
    'allocations_view', metadata,
    Column('orderid', String(255)),
    Column('sku', String(255)),
    Column('batchref', String(255)),
)
----
====

We add a second handler to the `Allocated` event:

[[new_handler_for_allocated]]
.Allocated event gets a new handler (src/allocation/messagebus.py)
====
[source,python]
----
EVENT_HANDLERS = {
    events.Allocated: [
        handlers.publish_allocated_event,
        handlers.add_allocation_to_read_model
    ],
----
====


Here's what our update-view-model code looks like:


[[update_view_model_1]]
.Update on allocation (src/allocation/handlers.py)
====
[source,python]
----

def add_allocation_to_read_model(
        event: events.Allocated, uow: unit_of_work.SqlAlchemyUnitOfWork,
):
    with uow:
        uow.session.execute(
            'INSERT INTO allocations_view (orderid, sku, batchref)'
            ' VALUES (:orderid, :sku, :batchref)',
            dict(orderid=event.orderid, sku=event.sku, batchref=event.batchref)
        )
        uow.commit()
----
====


And it'll work!


(OK you'll also need to handle deallocated:)


[[handle_deallocated_too]]
.A second listener for read model updates
====
[source,python]
[role="skip"]
----
events.Deallocated: [
    handlers.remove_allocation_from_read_model,
    handlers.reallocate
],

...

def remove_allocation_from_read_model(
        event: events.Deallocated, uow: unit_of_work.SqlAlchemyUnitOfWork,
):
    with uow:
        uow.session.execute(
            'DELETE FROM allocations_view '
            ' WHERE orderid = :orderid AND sku = :sku',
----
====

TODO: diagram

[[read_model_sequence_diagram]]
.Sequence diagram for read model
image::images/read_model_sequence_diagram.png[]
[role="image-source"]
----
[plantuml, read_model_sequence_diagram]
@startuml
actor User order 1
boundary Flask order 2
participant MessageBus order 3
participant "Domain Model" as Domain order 4
participant View order 9
database DB order 10

User -> Flask: POST to allocate Endpoint
Flask -> MessageBus : Allocate Command

MessageBus -> Domain : allocate()
MessageBus -> DB: commit write model
Domain -> MessageBus : raise Allocated event(s)
MessageBus -> DB : update view model

Flask -> User: 202 OK

User -> Flask: GET allocations endpoint
Flask -> View: get allocations
View -> DB: SELECT on view model
DB -> View: some allocations
View -> Flask: some allocations
Flask -> User: some allocations

@enduml
----


=== But Whyyyyyyy?

OK.  Horrible, right?  But also, kinda, surprisingly nice, considering?  Our
events and message bus give us a really nice place to do this sort of stuff,
_if we need to_.

And think how easy it'd be to swap our read model from Postgres to Redis or
Memcached? Super-simple.  _We don't even need to change the integration test_.

TODO: demo this.

// TODO (EJ) Some explicit discussion of CRUD vs CQRS might be good. I'd guess
// that there will be a lot readers coming to this book from Django.

So definitely don't do this. Ever.  Unless you really need to.  But, if you do
need to, see how easy the event-driven model makes it?

OK.  On that note, let's sally forth into our final chapter.
