[[chapter_07_external_events]]
== Event-Driven Architecture (using events to integrate microservices)

We've got a microservice with a web api, but what about other ways of talking
to other systems?  how does it know if, say, a shipment is delayed or the
quantity is amended?  how does it communicate to our warehouse system to say
that an order has been allocated and needs to be sent to a customer?

In this chapter we'd like to show how the events metaphor can be stretched
to encompass the way that we handle incoming and outgoing messages from the
system.


=== Using a Redis pubsub channel for integration

At MADE.com we use https://eventstore.org/[Eventstore] to convey messages
between systems, but a lightweight solution based on Redis pubsub channels
can work just fine, and are probably more familiar.

Here's how we might start with an end-to-end test.  We can use our existing
API to create batches, and then we'll test both inbound and outbound messages:


[[redis_e2e_test]]
.An end-to-end test for our pubsub model (tests/e2e/test_redis.py)
====
[source,python]
[role="non-head"]
----
@pytest.mark.usefixtures('postgres_db')
@pytest.mark.usefixtures('restart_api')
@pytest.mark.usefixtures('restart_redis_pubsub')
def test_change_batch_quantity_leading_to_reallocation():
    orderid, sku = random_ref('o'), random_ref('s')
    batch1, batch2 = random_ref('b1'), random_ref('b2')
    post_to_add_batch(batch1, sku, 10, '2011-01-02')
    post_to_add_batch(batch2, sku, 10, '2011-01-03')
    post_to_allocate(orderid, sku, 10, expected_batch=batch1)

    print('subscribing to allocated events')
    r = redis.Redis(**config.get_redis_host_and_port())
    pubsub = r.pubsub()
    pubsub.subscribe('line_allocated')  #<2>
    confirmation = wait_for(pubsub.get_message)
    assert confirmation['type'] == 'subscribe'

    print('sending change batch quantity for', batch1)
    r.publish('change_batch_quantity', json.dumps({  #<1>
        'batchid': batch1, 'sku': sku, 'qty': 5
    }))

    print('waiting for reallocation event')
    messages = []
    def check_messages():  #<2>
        messages.append(wait_for(pubsub.get_message))
        print(messages)
        data = json.loads(messages[-1]['data'])
        assert data['orderid'] == orderid
        assert data['batchid'] == batch2

    wait_for_assertion(check_messages)

----
====

Because this is an end-to-end test and our publish/subscribe model is
asynchronous, there's a bit of boilerplate to manage waiting, but
essentially:

<1> We'll use a channel called `change_batch_quantity` to send
    in our request to change the quantity for a batch.  In this
    case we deliberately change the quantity such that we expect
    an order to be reallocated to a different batch.

<2> And we'll listen to another channel called `line_allocated` to
    look out for the expected reallocation.


==== Redis is another thin adapter around our service layer


[[redis_pubsub_first_cut]]
.A first cut of a redis message listener (src/allocation/redis_pubsub.py)
====
[source,python]
[role="non-head"]
----
from allocation import config, orm, services, unit_of_work

r = redis.Redis(**config.get_redis_host_and_port())

def main():  #<1>
    orm.start_mappers()
    pubsub = r.pubsub()
    pubsub.subscribe('change_batch_quantity')

    for m in pubsub.listen():
        if m['type'] == 'subscribe':
            print('subscribed successfully')
            continue
        handle_change_batch_quantity(m)


def handle_change_batch_quantity(m):  #<2>
    print('handling', m)
    data = json.loads(m['data'])
    services.change_batch_quantity(
        ref=data['batchid'], qty=data['qty'],
        start_uow=unit_of_work.start
    )
----
====

//TODO: add some calls to logging.debug, where there used to be prints?

<1> Main subscribes us to the channel on load
<2> And our main job is to deserialize JSON, and pass it to the service
    layer, much like the Flask adapter does.


So we'll need a new service called `change_batch_quantity`.
    

=== Test-driving a new service at the service layer

Following the lessons learned in <<chapter_03_flask_api_and_service_layer>>,
we can operate in "high gear", and write our unit tests at the highest
possible level of abstraction, the service layer.  Here's what they might
look like:


[[service_layer_tests_for_change_batch_quantity]]
.Service layer tests for change_batch_quantity (tests/unit/test_services.py)
====
[source,python]
----
class TestChangeBatchQuantity:

    @staticmethod
    def test_changes_available_quantity():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 100, None, start_uow)
        [batch] = uow.products.get(sku='sku1').batches
        assert batch.available_quantity == 100
        services.change_batch_quantity('b1', 50, start_uow)
        assert batch.available_quantity == 50


    @staticmethod
    def test_deallocates_if_necessary():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)
        services.allocate('o1', 'sku1', 20, start_uow)
        services.allocate('o2', 'sku1', 20, start_uow)

        product = uow.products.get(sku='sku1')
        [batch] = product.batches
        assert batch.available_quantity == 10

        services.change_batch_quantity('b1', 25, start_uow)
        assert batch.available_quantity == 5
----
====


==== An internal event to express de-allocation

A batch might have dozens of orders allocated to it. Similarly to the "out of
stock" email, rather than doing deallocation and re-allocation in-line in the
service function, we can choose to clearly separate responsibility:

* For the system to be in a consistent state, batch quantity changes should
  cause deallocations, if necessary

* But reallocation can happen in a separate unit of work.

So we use internal/domain events to capture this distinction:


[[expect_event_for_deallocated]]
.A domain event for Deallocation (tests/unit/test_services.py)
====
[source,python]
----
    @staticmethod
    def test_emits_deallocation_event():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)
        services.allocate('o1', 'sku1', 40, start_uow)

        product = uow.products.get(sku='sku1')
        services.change_batch_quantity('b1', 30, start_uow)

        assert product.events[-1] == events.Deallocated('o1', 'sku1', 40)
----
====

==== Implementation


[[change_quantity_service]]
.Service delegates to model layer (src/allocation/services.py)
====
[source,python]
----
def change_batch_quantity(ref: str, qty: int, start_uow):
    with start_uow() as uow:
        product = uow.products.get_by_batchid(batchid=ref)
        product.change_batch_quantity(ref=ref, qty=qty)
        uow.commit()
----
====

(along the way we need a new query type on our repository)

[[get_by_batchid]]
.A new query type on our repository
====
[source,python]
----
class ProductRepository:
    #...

    @capture_seen
    def get(self, sku):
        #...

    @capture_seen
    def get_by_batchid(self, batchid):
        return self.session.query(model.Product).join(model.Batch).filter(
            orm.batches.c.reference == batchid,
        ).first()
----
====

TODO: discuss alternative methods on repository.


[[model_layer_change]]
.Our model evolves to capture the new requirement (src/allocation/model.py)
====
[source,python]
----
class Product:
    #...

    def change_batch_quantity(self, ref: str, qty: int):
        batch = next(b for b in self.batches if b.reference == ref)
        batch._purchased_quantity = qty
        while batch.available_quantity < 0:
            line = batch.deallocate_one()
            self.events.append(
                events.Deallocated(line.orderid, line.sku, line.qty)
            )
#...

class Batch:
    #....

    def deallocate_one(self) -> OrderLine:
        return self._allocations.pop()
----
====


TODO: should we have `Batch.change_purchased_quantity`?  But how to
    pass events back up to Product object?


=== New handlers for allocated and deallocated events

What we need to do is pretty straightforward:


[[new_handlers]]
.New handlers for allocate and reallocate (src/allocation/messagebus.py)
====
[source,python]
----
def reallocate(
        event: events.Deallocated, start_uow
):
    services.allocate(event.orderid, event.sku, event.qty, start_uow)  #<1>


def publish_allocated_event(
        event: events.Allocated, start_uow, publish=redis_pubsub.publish
):
    publish('line_allocated', event)  #<2>


HANDLERS = {
    events.OutOfStock: [handle_out_of_stock],
    events.Allocated: [publish_allocated_event],
    events.Deallocated: [reallocate],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====

<1> reallocate just calls our existing service-layer `allocate` function
<2> and publishing an external event is very easy too:


[[redis_publish]]
.Publishing an event as JSON (src/allocation/redis_pubsub.py)
====
[source,python]
----
def publish(channel, event):
    r.publish(channel, json.dumps(asdict(event)))
----
====



==== Testing handlers

Because our handlers have an explicit dependency on `start_uow`,
we can test them individually:

[[test_handler_directly]]
.Testing the reallocate handler directly
====
[source,python]
----
    @staticmethod
    def test_reallocation_handler():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)

        [reallocate] = messagebus.HANDLERS[events.Deallocated]
        e = events.Deallocated(orderid='o1', sku='sku1', qty=10)
        reallocate(e, start_uow=start_uow)

        [batch] = uow.products.get(sku='sku1').batches
        assert batch.available_quantity == 40
----
====

But it's a little fiddly.


=== Services can become event handlers

There are a few code smells hanging around:

* primitive obsession:  we switched to using primitives in our service
  layer because they freed us from depending on the domain model, but
  our adapters, flask and redis, are spending a lot of time wrangling
  strings and integer arguments.  Perhaps we could capture the structure
  of the data required to call a service using some sort of reusable class?

* services and event handlers are quite similar.   They have dependencies
  on the UoW and other external adapters, and they even sometimes call each
  other.  More fundamentally, they're both ways of reacting to some sort of
  command or event, whether it's internal or external.


.A handler and a service
====
[source,python]
[role="skip"]
----
def reallocate(
        event: events.Deallocated, start_uow
):
    services.allocate(event.orderid, event.sku, event.qty, start_uow)

#...

def allocate(orderid: str, sku: str, qty: int, start_uow) -> str:
----
====

Let's see what would happen if we pushed the event-driven metaphor a little
further, and made all the services into event handlers too.  Event classes
will solve the "primitive obsession" problems, and the message bus will become
the core of our application:



[[full_messagebus]]
.The messagebus grows (src/allocation/messagebus.py)
====
[source,python]
----
def handle(start_uow, events_: List[events.Event]):
    #...


HANDLERS = {
    events.BatchCreated: [handlers.add_batch],
    events.BatchQuantityChanged: [handlers.change_batch_quantity],
    events.AllocationRequest: [handlers.allocate],
    events.Deallocated: [handlers.allocate],
    events.OutOfStock: [handlers.send_out_of_stock_email],
    events.Allocated: [handlers.publish_allocated_event],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====


We define a series of new events, which capture the inputs, outputs, and
internal message structures of our system in a single place:


[[more_events]]
.More events
====
[source,python]
----
@dataclass
class AllocationRequest(Event):
    orderid: str
    sku: str
    qty: int

#...

@dataclass
class BatchCreated(Event):
    ref: str
    sku: str
    qty: int
    eta: Optional[date] = None

@dataclass
class BatchQuantityChanged(Event):
    ref: str
    qty: int
----
====


And we combine our services and handlers into a single file,
_handlers.py_:


[[handlers_dot_py]]
.Handlers and services are the same thing, really (src/allocation/handlers.py)
====
[source,python]
----
def add_batch(start_uow, event: events.BatchCreated):
    with start_uow() as uow:
        product = uow.products.get(sku=event.sku)
        #...

def change_batch_quantity(start_uow, event: events.BatchQuantityChanged):
    #...

def allocate(start_uow, event: events.AllocationRequest) -> str:
    #...

def send_out_of_stock_email(
        start_uow, event: events.OutOfStock, send_email=email.send
):
    #...

def publish_allocated_event(
        start_uow, event: events.Allocated, publish=redis_pubsub.publish
):
    #...
----
====


Now the places in our code where we need to parse external input have a clearly
defined data structure for making requests into the system, the events, and a
single entrypoint into the system, the message bus:


[[flask_with_events]]
.Flask creates events and puts them on the messagebus. (src/allocation/flask_app.py)
====
[source,python]
----
@app.route("/add_batch", methods=['POST'])
def add_batch():
    eta = request.json['eta']
    if eta is not None:
        eta = datetime.fromisoformat(eta).date()
    event = events.BatchCreated(
        request.json['ref'], request.json['sku'], request.json['qty'], eta,
    )
    messagebus.handle(unit_of_work.start, [event])
    return 'OK', 201
----
====


Redis now looks very similar

[[redis_with_events]]
.And so does redis (src/allocation/redis_pubsub.py)
====
[source,python]
----
def handle_change_batch_quantity(m):
    data = json.loads(m['data'])
    event = events.BatchQuantityChanged(ref=data['batchid'], qty=data['qty'])
    messagebus.handle(unit_of_work.start, [event])
----
====


And our system is now entirely event-driven.

.Internal vs External events
*******************************************************************************
It's a good idea to keep the distinction between internal and external events
clear.  Some events may come from the outside, and some events may get upgraded
and published externally, but not all of them.  This is particularly important
if you get into event sourcing (TODO: link)

*******************************************************************************



=== What have we achieved?

* events are simple dataclasses that define the data structures for inputs,
  outputs, and internal messages within our system.  this is quite powerful
  from a DDD standpoint, since events often translate really well into
  business language; cf. "event storming" (TODO: link)

* handlers are the way we react to events.   They can call down to our
  model, or they can call out to external services.  We can define multiple
  handlers for a single event if we want to.  handlers can also raise other
  events.  This allows us to be very granular about what a handler does,
  and really stick to the SRP.

* events can come _from_ the outside, but they can also be published
  externally -- our `publish` handler converts an event to a message
  on a redis channel. We use events to talk to the outside world.

We've added bit of complexity to our architecture, but hopefully you can
see how we've now made it very easy to plug in almost any new requirement
from the business, whether it's a new use case, a new integration with
one of our internal systems, or an integration with external systems.


