[[chapter_07_external_events]]
== Event-Driven Architecture (using events to integrate microservices)


We've got a microservice with an web api, but what about other ways of talking
to other systems?  how does it know if, say, a shipment is delayed or the
quantity is amended?  how does it communicate to our warehouse system to say
that an order has been allocated and needs to be sent to a customer?

In this chapter we'd like to show how the events metaphor can be stretched
to encompass the way that we handle incoming and outgoing messages from the
system.

=== Using a Redis pubsub channel for integration

At MADE.com we use https://eventstore.org/[Eventstore] to convey messages
between systems, but a lightweight solution based on Redis pubsub channels
can work just fine, and are probably more familiar.

Here's how we might start with an end-to-end test.  We can use our existing
API to create batches, and then we'll test both inbound and outbound messages:


[[redis_e2e_test]]
.An end-to-end test for our pubsub model (tests/e2e/test_redis.py)
====
[source,python]
----
@pytest.mark.usefixtures('postgres_db')
@pytest.mark.usefixtures('restart_api')
@pytest.mark.usefixtures('restart_redis_pubsub')
def test_change_batch_quantity_leading_to_reallocation():
    orderid, sku = random_ref('o'), random_ref('s')
    batch1, batch2 = random_ref('b1'), random_ref('b2')
    post_to_add_batch(batch1, sku, 10, '2011-01-02')
    post_to_add_batch(batch2, sku, 10, '2011-01-03')
    post_to_allocate(orderid, sku, 10, expected_batch=batch1)

    print('subscribing to allocated events')
    r = redis.Redis(**config.get_redis_host_and_port())
    pubsub = r.pubsub()
    pubsub.subscribe('line_allocated')  #<2>
    confirmation = wait_for(pubsub.get_message)
    assert confirmation['type'] == 'subscribe'

    print('sending change batch quantity for', batch1)
    r.publish('change_batch_quantity', json.dumps({  #<1>
        'batchid': batch1, 'sku': sku, 'qty': 5
    }))

    print('waiting for reallocation event')
    messages = []
    def check_messages():  #<2>
        messages.append(wait_for(pubsub.get_message))
        print(messages)
        data = json.loads(messages[-1]['data'])
        assert data['orderid'] == orderid
        assert data['batchid'] == batch2

    wait_for_assertion(check_messages)

----
====

Because this is an end-to-end test and our publish/subscribe model is
asynchronous, there's a bit of boilerplate to manage waiting, but
essentially:

<1> We'll use a channel called `change_batch_quantity` to send
    in our request to change the quantity for a batch.  In this
    case we deliberately change the quantity such that we expect
    an order to be reallocated to a different batch.

<2> And we'll listen to another channel called `line_allocated` to
    look out for the expected reallocation.


==== Redis is another thin adapter around our service layer


[[redis_pubsub_first_cut]]
.A first cut of a redis message listener (src/allocation/redis_pubsub.py)
====
[source,python]
----
from allocation import config, orm, services, unit_of_work

r = redis.Redis(**config.get_redis_host_and_port())

def main():  #<1>
    orm.start_mappers()
    pubsub = r.pubsub()
    pubsub.subscribe('change_batch_quantity')

    for m in pubsub.listen():
        if m['type'] == 'subscribe':
            continue
        handle_change_batch_quantity(m)


def handle_change_batch_quantity(m):  #<2>
    data = json.loads(m['data'])
    services.change_batch_quantity(
        ref=data['batchid'], qty=data['qty'],
        start_uow=unit_of_work.start
    )
----
====

//TODO: add some calls to logging.debug, where there used to be prints?

<1> Main subscribes us to the channel on load
<2> And our main job is to deserialize JSON, and pass it to the service
    layer, much like the Flask adapter does.


So we'll need a new service called `change_batch_quantity`.
    

=== Test-driving a new service at the service layer

Following the lessons learned in <<chapter_03_flask_api_and_service_layer>>,
we can operate in "high gear", and write our unit tests at the highest
possible level of abstraction, the service layer.  Here's what they might
look like:


[[service_layer_tests_for_change_batch_quantity]]
.Service layer tests for change_batch_quantity (tests/unit/test_services.py)
====
[source,python]
----
class TestChangeBatchQuantity:

    @staticmethod
    def test_changes_available_quantity():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 100, None, start_uow)
        [batch] = uow.products.get(sku='sku1').batches
        assert batch.available_quantity == 100
        services.change_batch_quantity('b1', 50, start_uow)
        assert batch.available_quantity == 50


    @staticmethod
    def test_deallocates_if_necessary():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)
        services.allocate('o1', 'sku1', 20, start_uow)
        services.allocate('o2', 'sku1', 20, start_uow)

        product = uow.products.get(sku='sku1')
        [batch] = product.batches
        assert batch.available_quantity == 10

        services.change_batch_quantity('b1', 25, start_uow)
        assert batch.available_quantity == 5
----
====


==== An internal event to express de-allocation

A batch might have dozens of orders allocated to it. Similarly to the "out of
stock" email, rather than doing deallocation and re-allocation in-line in the
service function, we can choose to clearly separate responsibility:

* For the system to be in a consistent state, batch quantity changes should
  cause deallocations, if necessary

* But reallocation can happen in a separate unit of work.

So we use internal/domain events to capture this distinction:


[[expect_event_for_deallocated]]
.A domain event for Deallocation (tests/unit/test_services.py)
====
[source,python]
----
    @staticmethod
    def test_emits_deallocation_event():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)
        services.allocate('o1', 'sku1', 40, start_uow)

        product = uow.products.get(sku='sku1')
        services.change_batch_quantity('b1', 30, start_uow)

        assert product.events[-1] == events.Deallocated('o1', 'sku1', 40)
----
====

==== Implementation


[[change_quantity_service]]
.Service delegates to model layer (src/allocation/services.py)
====
[source,python]
----
def change_batch_quantity(ref: str, qty: int, start_uow):
    with start_uow() as uow:
        product = uow.products.get_by_batchid(batchid=ref)
        product.change_batch_quantity(ref=ref, qty=qty)
        uow.commit()
----
====

(along the way we need a new query type on our repository)

[[get_by_batchid]]
.A new query type on our repository
====
[source,python]
----
class ProductRepository:
    #...

    @capture_seen
    def get(self, sku):
        #...

    @capture_seen
    def get_by_batchid(self, batchid):
        return self.session.query(model.Product).join(model.Batch).filter(
            orm.batches.c.reference == batchid,
        ).first()
----
====

TODO: discuss alternative methods on repository.


[[model_layer_change]]
.Our model evolves to capture the new requirement (src/allocation/model.py)
====
[source,python]
----
class Product:
    #...

    def change_batch_quantity(self, ref: str, qty: int):
        batch = next(b for b in self.batches if b.reference == ref)
        batch._purchased_quantity = qty
        while batch.available_quantity < 0:
            line = batch.deallocate_one()
            self.events.append(
                events.Deallocated(line.orderid, line.sku, line.qty)
            )
#...

class Batch:
    #....

    def deallocate_one(self) -> OrderLine:
        return self._allocations.pop()
----
====


TODO: should we have `Batch.change_purchased_quantity`?  But how to
    pass events back up to Product object?


=== New handlers for allocated and deallocated events

What we need to do is pretty straightforward:


[[new_handlers]]
.New handlers for allocate and reallocate (src/allocation/messagebus.py)
====
[source,python]
----
def reallocate(
        event: events.Deallocated, start_uow
):
    services.allocate(event.orderid, event.sku, event.qty, start_uow)  #<1>


def publish_allocated_event(
        event: events.Allocated, start_uow, publish=redis_pubsub.publish
):
    publish('line_allocated', event)  #<2>


HANDLERS = {
    events.OutOfStock: [handle_out_of_stock],
    events.Allocated: [publish_allocated_event],
    events.Deallocated: [reallocate],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====

<1> reallocate just calls our existing service-layer `allocate` function
<2> and publishing an external event is very easy too:


[[redis_publish]]
.Publishing an event as JSON (src/allocation/redis_pubsub.py)
====
[source,python]
----
def publish(channel, event):
    r.publish(channel, json.dumps(asdict(event)))
----
====



==== Testing handlers

Because our handlers have an explicit dependency on `start_uow`,
we can test them individually:

[[test_handler_directly]]
.Testing the reallocate handler directly
====
[source,python]
----
    @staticmethod
    def test_reallocation_handler():
        uow = FakeUnitOfWork()
        start_uow = lambda: nullcontext(uow)
        services.add_batch('b1', 'sku1', 50, None, start_uow)

        [reallocate] = messagebus.HANDLERS[events.Deallocated]
        e = events.Deallocated(orderid='o1', sku='sku1', qty=10)
        reallocate(e, start_uow=start_uow)

        [batch] = uow.products.get(sku='sku1').batches
        assert batch.available_quantity == 40
----
====

But it's a little fiddly.


=== Internal vs External events

bla bla TODO


=== Outline/TODO

* [line-through]#E2E test#
* [line-through]#first cut of _redis_pubsub.py_#
* [line-through]#test-drive `services.change_batch_quantity` at service layer#
* [line-through]#brief aside on `ProductRepository.get_by_batchid()`#
* [line-through]#add events for allocated, deallocated#
* [line-through]#and handlers for both#
* discuss internal vs external events

* stop and reflect:
    * handlers call services
    * services raise events which call handlers which call services
    * primitive obsession code smell
    * dependencies are a bit all over the place

* => introduce commands
* all services become handlers

* segue to next chapter on dependency mgmt

