[[chapter_07_external_events]]
== Event-Driven Architecture (Using Events to Integrate Microservices)

//TODO get rid of bullets

In this chapter:

* We'll see how to use events to communicate between multiple microservices.

* We'll show how our service-layer lets us easily replace an HTTP API with an
  asynchronous message bus.

* We'll rebuild our application as a message-processor.

TODO: DIAGRAM GOES HERE


We've got a microservice with a web API, but what about other ways of talking
to other systems?  How does it know if, say, a shipment is delayed or the
quantity is amended?  How does it communicate to our warehouse system to say
that an order has been allocated and needs to be sent to a customer?

In this chapter we'd like to show how the events metaphor can be extended
to encompass the way that we handle incoming and outgoing messages from the
system.


=== An External Event Triggers Internal Invents

We learn about the need to change batch quantities when they're already
in the system.  Perhaps someone made a mistake on the number in the manifest,
or perhaps some sofas fell off a truck. Following a conversation with the
business,footnote:[Modelling things with events extends out from the code
into real life conversations! Look up "Event Storming" for more inspiration],
we model the situation as in <<batch_changed_events_flow_diagram>>:


[[batch_changed_events_flow_diagram]]
.batch quantity changed means deallocate and reallocate
image::images/batch_changed_events_flow_diagram.png[]
[role="image-source"]
----
[ditaa, batch_changed_events_flow_diagram]
+----------+    /----\      +------------+       +------------+
| Batch    |--> |RULE| -->  | Deallocate | ----> | Reallocate |
| Quantity |    \----/      +------------+-+     +------------+-+
| Changed  |                  | Deallocate | ----> | Reallocate |
+----------+                  +------------+-+     +------------+-+
                                | Deallocate | ----> | Reallocate |
                                +------------+       +------------+
----

An event we'll called _batch quantity changed_ should lead us to change the
quantity on the batch, yes, but also to apply a _business rule_: if the new
quantity drops to less than the total already allocated, we need to
_deallocate_  those orders from that batch. Then, we want to _reallocate_ them
to other batches.

////
TODO (ej) Is "reallocate" as a separate concept necessary? Or is that just covered by "allocate"?
     I find myself being a bit confused by some of the text, because it feels like
     "reallocate" = "deallocate" + "allocate", and just "deallocation" seems resonable
     for things like cancellations.
////


For now, our message bus only handles internal events.  We'll use those to express the need
to reallocate after deallocation, using a `Deallocated` event.  Once we've got everything
working, we'll switch to "everything is events":  we'll use events to express
all our external inputs, including messages coming into the API, so we'll make the
service layer into event handlers, and _everything_ will go via the message bus.

////
TODO: consider re-ordering this chapter as follows:

1. make the change easy:
2. introduce new external events, BatchQuantityChanged and Allocated
3. introduce new internal event, Deallocated
4. change API to use events, AllocationRequest and BatchCreated, merge service layer and message handlers
5. make the easy change, add redis and its handler
////


But first, an end-to-end test to drive us towards a working solution.


=== Using a Redis Pubsub Channel for Integration

When moving towards events as an integration solution, you need to choose
some sort of technology for passing those events from one system to another.
We need our systems to be able to publish events to some central service, and
we need some way for other systems to be able to "subscribe" to different types
of messages, and pick them up asynchronously from some sort of queue.

At MADE.com we use https://eventstore.org/[Eventstore];  Kafka or RabbitMQ
are valid alternatives. A lightweight solution based on Redis
https://redis.io/topics/pubsub[pubsub channels] can also work just fine, and we
think more of our readers will be familiar with Redis, so we thought we'd that
for this book.
////
TODO (ej)  I think the differences between the families of messaging implementations based 
      on streams (Kafka, EventStore, Redis Streams, Kinesis), pub-sub (Redis PubSub, SNS, etc.)
      and queuing (RabbitMQ, Redis Queues) are significant enough to call out here. They're
      not always easily interchangeable, due to concerns like message ordering, failure handling, 
      and idempotency.

      With Redis Pub-Sub specifically, I would wonder how you deal with client side failures and lost
      messages.
////


Here's how we might start with an end-to-end test.  We can use our existing
API to create batches, and then we'll test both inbound and outbound messages:


[[redis_e2e_test]]
.An end-to-end test for our pubsub model (tests/e2e/test_external_events.py)
====
[source,python]
[role="non-head"]
----
def test_change_batch_quantity_leading_to_reallocation():
    # start with two batches and an order allocated to one of them  #<1>
    orderid, sku = random_orderid(), random_sku()
    earlier_batch, later_batch = random_batchref('old'), random_batchref('newer')
    api_client.post_to_add_batch(earlier_batch, sku, qty=10, eta='2011-01-02')  <2>
    api_client.post_to_add_batch(later_batch, sku, qty=10, eta='2011-01-02')  <2>
    response = api_client.post_to_allocate(orderid, sku, 10)  <2>
    assert response.json()['batchref'] == earlier_batch

    subscription = redis_client.subscribe_to('line_allocated')  #<3>

    # change quantity on allocated batch so it's less than our order  #<1>
    redis_client.publish_message('change_batch_quantity', {  #<3>
        'batchref': earlier_batch, 'qty': 5
    })

    # wait until we see a message saying the order has been reallocated  #<1>
    messages = []
    def assert_new_allocation_published():  #<4>
        messages.append(wait_for(subscription.get_message))  #<4>
        print(messages)
        data = json.loads(messages[-1]['data'])
        assert data['orderid'] == orderid
        assert data['batchref'] == later_batch
        return True

    wait_for(assert_new_allocation_published)  #<4>
----
====

<1> You can read the story of what's going on in this test from the comments:
    we want to send an event into the system that causes an order line to be
    reallocated, and we see that reallocation come out as an event in redis too.

<2> `api_client` is a little helper that we refactored out to share between
    our two test types, it wraps our calls to `requests.post`

<3> `redis_client` is another test little test helper, the details of which
    don't really matter; its job is to be able to send and receive messages
    from various Redis channels. We'll use a channel called
    `change_batch_quantity` to send in our request to change the quantity for a
    batch, and we'll listen to another channel called `line_allocated` to
    look out for the expected reallocation.

<4> The last little test helper is a `wait_for` function.  Because we're
    moving to asynchronous model, we need our tests to be able to wait until
    something happens.  To do that, we wrap our assertions inside a function.
    We'll show the code for `wait_for` below, for the curious:

////
TODO (ej) Minor comment: This e2e test might not be safe or repeatable as part of a
     larger test suite, since test run data is being persisted in redis.
     Purging the queue as part of setup will help, but it would still have problems
     with running tests in parallel. Not sure if it's worth bringing up as it might 
     be too much of a digression.
////

[[wait_for]]
.A helper function for testing asynchronous behavior (tests/e2e/wait_for.py)
====
[source,python]
----
def wait_for(fn):
    """
    Keep retrying a function, catching any exceptions, until it returns something truthy,
    or we hit a timeout.
    """
    timeout = time.time() + 3
    while time.time() < timeout:
        try:
            r = fn()
            if r:
                return r
        except:
            if time.time() > timeout:
                raise
        time.sleep(0.1)
    pytest.fail(f'function {fn} never returned anything truthy')
----
====
////
TODO (ej)  Not 100% sure of the necessity of wait_for. According to the source code, redis-py
      subscription.get_message already takes a timeout, and under what conditions would
      a re-triable exception be thrown?

     If you do need to poll and retry, the tenacity library may be simpler than wait_for. 
////


==== Redis is Another Thin Adapter Around our Service Layer


[[redis_pubsub_first_cut]]
.A first cut of a redis message listener (src/allocation/redis_pubsub.py)
====
[source,python]
[role="non-head"]
----
r = redis.Redis(**config.get_redis_host_and_port())


def main():
    orm.start_mappers()
    pubsub = r.pubsub(ignore_subscribe_messages=True)
    pubsub.subscribe('change_batch_quantity')  #<1>

    for m in pubsub.listen():
        handle_change_batch_quantity(m)


def handle_change_batch_quantity(m):
    logging.debug('handling %s', m)
    data = json.loads(m['data'])  #<2>
    services.change_batch_quantity(  #<2>
        ref=data['batchref'], qty=data['qty'],
        uow=unit_of_work.SqlAlchemyUnitOfWork(),
    )


def publish(channel, event):  #<3>
    logging.debug('publishing: channel=%s, event=%s', channel, event)
    r.publish(channel, json.dumps(asdict(event)))


if __name__ == '__main__':
    main()
----
====

<1> `main()` subscribes us to the `change_batch_quantity` channel on load

<2> And our main job as an entrypoint to the system is to deserialize JSON, and
    pass it to the service layer, much like the Flask adapter does.

<3> We also provide a helper function to publish events back into Redis.

// TODO (DS): I'm generally just a bit lost here. Why do we need to do this? I
// thought domain events are more about saying that something happened rather
// than using commands...?

// BOB: This should be covered by a context or component diagram to show how
// Procurement drives changes in Allocation

So we'll need a new service called `change_batch_quantity`.


=== Test-Driving a New Service at the Service Layer

Following the lessons learned in <<chapter_03_service_layer>>,
we can operate in "high gear," and write our unit tests at the highest
possible level of abstraction, the service layer.  Here's what they might
look like:


[[service_layer_tests_for_change_batch_quantity]]
.Service layer tests for change_batch_quantity (tests/unit/test_services.py)
====
[source,python]
[role="non-head"]
----
    def test_changes_available_quantity():
        uow = FakeUnitOfWork()
        services.add_batch("batch1", "ADORABLE-SETTEE", 100, None, uow)
        [batch] = uow.products.get(sku="ADORABLE-SETTEE").batches
        assert batch.available_quantity == 100

        services.change_batch_quantity("batch1", 50, uow)  #<1>

        assert batch.available_quantity == 50  #<1>

    ...

    def test_reallocates_if_necessary():
        uow = FakeUnitOfWork()
        services.add_batch("batch1", "INDIFFERENT-TABLE", 50, None, uow)
        services.add_batch("batch2", "INDIFFERENT-TABLE", 50, date.today(), uow)
        services.allocate("order1", "INDIFFERENT-TABLE", 20, uow)
        services.allocate("order2", "INDIFFERENT-TABLE", 20, uow)
        [batch1, batch2] = uow.products.get(sku="sku1").batches
        assert batch1.available_quantity == 10  #<2>

        services.change_batch_quantity("batch1", 25, uow)  #<2>

        # order1 or order2 will be deallocated, so we"ll have 25 - 20 * 1
        assert batch1.available_quantity == 5  #<2>
        # and 20 will be reallocated to the next batch
        assert batch2.available_quantity == 30  #<2>
----
====

<1> The simple case would be trivially easy to implement, we just
    modify a quantity.

<2> But if we try and change the quantity so that there's less than
    has been allocated, we'll need to deallocate at least one order,
    and we expect to reallocated it to a new batch


==== Adding Some Internal Events to Express De-Allocation

A batch might have dozens of orders allocated to it. Similarly to the "out of
stock" email, rather than doing deallocation and re-allocation in-line in the
service function, we can choose to clearly separate responsibility:

* For the system to be in a consistent state, batch quantity changes should
  immediately cause deallocations, if necessary.

* But reallocation can happen in a separate unit of work.

So our flow would look like <<reallocation_sequence_diagram>>:

[[reallocation_sequence_diagram]]
.Sequence diagram for reallocation flow
image::images/reallocation_sequence_diagram.png[]
[role="image-source"]
....
[plantuml, reallocation_sequence_diagram]
@startuml
Redis -> Service_Layer : invoke change_batch_quantity service

group Unit of Work 1
    Service_Layer -> Domain_Model : change batch quantity
    Domain_Model -> Message_Bus : emit Deallocated event(s)
end

Message_Bus -> Service_Layer : re-allocate

group Unit(s) of Work 2 (or more)
    Service_Layer -> Domain_Model : allocate
    Domain_Model -> Message_Bus : emit Allocated event(s)
end

Message_Bus -> Redis : publish to line_allocated channel
@enduml
....

////
TODO (ej)  There is a minor but important technical point here, I think, that could be a source
      of confusion.  The UOW and session commit are not exactly synonymous as the events are 
      not actually emitted until after the UOW "ends".  Otherwise you could end up with 
      a race or skew on the persisted state. (Or would that be prevented by re-using the same uow+session
      instance in the event handlers?)

      I am unsure how to present that information without adding a lot of detail to the sequence
      diagram.

////

Here's what our new internal events will look like:

[[two_new_events]]
.Allocated and Deallocated events (src/allocation/events.py)
====
[source,python]
----
@dataclass
class Allocated(Event):
    orderid: str
    sku: str
    qty: int
    batchref: str

@dataclass
class Deallocated(Event):
    orderid: str
    sku: str
    qty: int
----
====



==== Implementation

[[change_quantity_service]]
.Service delegates to model layer (src/allocation/services.py)
====
[source,python]
[role="non-head"]
----
def change_batch_quantity(
        ref: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
):
    with uow:
        product = uow.products.get_by_batchref(batchref=ref)
        product.change_batch_quantity(ref=ref, qty=qty)
        uow.commit()
----
====
// TODO (DS): Indentation looks off


(along the way we need a new query type on our repository)

[[get_by_batchref]]
.A new query type on our repository (src/allocation/repository.py)
====
[source,python]
----
class AbstractRepository(abc.ABC):
    ...

    def get(self, sku):
        ...

    def get_by_batchref(self, batchref):
        p = self._get_by_batchref(batchref)
        if p:
            self.seen.add(p)
        return p

    @abc.abstractmethod
    def _add(self, product):
        raise NotImplementedError

    @abc.abstractmethod
    def _get(self, sku):
        raise NotImplementedError

    @abc.abstractmethod
    def _get_by_batchref(self, batchref):
        raise NotImplementedError




class SqlAlchemyRepository(AbstractRepository):
    ...

    def _get(self, sku):
        return self.session.query(model.Product).filter_by(sku=sku).first()

    def _get_by_batchref(self, batchref):
        return self.session.query(model.Product).join(model.Batch).filter(
            orm.batches.c.reference == batchref,
        ).first()

----
====

And on our fakerepository too:

[[fakerepo_get_by_batchref]]
.Updating the fake repo too (tests/unit/test_services.py)
====
[source,python]
[role="non-head"]
----
class FakeRepository(repository.AbstractRepository):
    ...

    def _get(self, sku):
        return next((p for p in self._products if p.sku == sku), None)

    def _get_by_batchref(self, batchref):
        return next((
            p for p in self._products for b in p.batches
            if b.reference == batchref
        ), None)
----
====


You may be starting to worry that maintaining these fakes is going to be a
maintenance burden.  There's no doubt that it is work, but in our experience
it's not a lot of work.  Once your project is up and running, the interface for
your repository and UoW abstractions really don't change much.  And if you're
using ABC's, they'll help remind you when things get out of sync.

Because we have a single fake for each of our dependencies, we save a lot of
repetitive set up in our tests, so this approach pays off pretty quickly.

////
TODO (ej)  This will be a comon question, I'm sure.  The other option
      would be to use a mock or patch, which have their own burdens.
////

TODO: discuss finder methods on repository.


We add the new method to the model, which does the quantity change
and deallocation(s) inline, and publishes a new event.  We also
modify the existing allocate function to publish an event.


[[change_batch_model_layer]]
.Our model evolves to capture the new requirement (src/allocation/model.py)
====
[source,python]
----
class Product:
    #...
    def allocate(self, line: OrderLine) -> str:
        try:
            ...
            batch.allocate(line)
            self.events.append(events.Allocated(
                line.orderid, line.sku, line.qty, batch.reference
            ))
    ...

    def change_batch_quantity(self, ref: str, qty: int):
        batch = next(b for b in self.batches if b.reference == ref)
        batch._purchased_quantity = qty
        while batch.available_quantity < 0:
            line = batch.deallocate_one()
            self.events.append(
                events.Deallocated(line.orderid, line.sku, line.qty)
            )
#...

class Batch:
    #...

    def deallocate_one(self) -> OrderLine:
        return self._allocations.pop()
----
====



=== New Handlers for Allocated and Deallocated Events

// TODO (DS): I feel I'm having to hold too much in my brain at once....is
// there a way of communicating  the deallocation logic separately from the
// event driven stuff?

// (HP) maybe present events before the rest?

The handlers themselves aren't very complicated:


[[change_batch_new_handlers]]
.New handlers for allocate and reallocate (src/allocation/messagebus.py)
====
[source,python]
[role="non-head"]
----
def reallocate(
        event: events.Deallocated, uow: unit_of_work.AbstractUnitOfWork
):
    services.allocate(event.orderid, event.sku, event.qty, uow=uow)  #<1>


def publish_allocated_event(
        event: events.Allocated, uow: unit_of_work.AbstractUnitOfWork,
):
    redis_pubsub.publish('line_allocated', event)  #<2>


HANDLERS = {
    events.OutOfStock: [send_out_of_stock_notification],
    events.Allocated: [publish_allocated_event],
    events.Deallocated: [reallocate],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====

// TODO (DS): Again too much indent in function sigs?

<1> reallocate just calls our existing service-layer `allocate` function
<2> and publishing an external event is very easy too:

// TODO (DS): It would be nice to see a diagram of the system at this point.

//TODO, type hinting hints, use from __future__ import annotations


[[redis_publish]]
.Publishing an event as JSON (src/allocation/redis_pubsub.py)
====
[source,python]
----
def publish(channel, event):
    logging.debug('publishing: channel=%s, event=%s', channel, event)
    r.publish(channel, json.dumps(asdict(event)))
----
====


==== But Handlers Do Now Need a UoW

TODO: Introduce the infrastrutural changes at the end of the chapter so as not to interrupt flow.

Our event handlers do now need a UoW.  We make a small modification
to the main `messagebus.handle()` function:

// TODO (DS): This feels important, but I'm not sure why - slightly lost. Would
// it be better just to have used this structure from the beginning?

////
TODO (ej) Devil's advocate:  If your messagebus.handle processes half the events
     in the list, then drops the rest on the floor due to a db network outage
     or being OOM killed, how do you mitigate problems cause by the lost messages?
////

[[handle_takes_uow]]
.Handle takes a UoW (src/allocation/messagebus.py)
====
[source,python]
[role="non-head"]
----
def handle(events_: List[events.Event], uow: unit_of_work.AbstractUnitOfWork):
    while events_:
        event = events_.pop(0)
        for handler in HANDLERS[type(event)]:
            handler(event, uow=uow)
----
====


And to _unit_of_work.py_:


[[uow_passes_self_to_messagebus]]
.UoW passes self to message bus (src/allocation/unit_of_work.py)
====
[source,python]
----
class AbstractUnitOfWork(abc.ABC):
    ...

    def commit(self):
        self._commit()
        for obj in self.products.seen:
            messagebus.handle(obj.events, uow=self)  #<1>
----
====

<1> The UoW passes itself to the messagebus.


And that will get us to passing tests.  Things are starting to feel a little
messy, however.



=== Services Can Become Event Handlers

Let's take a look at our services and message handlers side-by-side:


[[halfway_point]]
.Services recap (src/allocation/services.py)
====
[source,python]
[role="non-head"]
----
def add_batch(
        ref: str, sku: str, qty: int, eta: Optional[date],
        uow: unit_of_work.AbstractUnitOfWork
):
...
def allocate(
        orderid: str, sku: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
) -> str:
...
def change_batch_quantity(
        ref: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
):
----
====


[[handlers_recap]]
.Handlers recap (src/allocation/messagebus.py)
====
[source,python]
[role="non-head"]
----
def send_out_of_stock_notification(
        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork
):
...
def reallocate(
        event: events.Deallocated, uow: unit_of_work.AbstractUnitOfWork
):
    services.allocate(event.orderid, event.sku, event.qty, uow=uow)
...
def publish_allocated_event(
        event: events.Allocated, uow: unit_of_work.AbstractUnitOfWork,
):
----
====


There are a few code smells hanging around:

* primitive obsession:  we switched to using primitives in our service
  layer because they freed us from depending on the domain model, but
  our adapters, flask and redis, are spending a lot of time wrangling
  strings and integer arguments.  Perhaps we could capture the structure
  of the data required to call a service using some sort of reusable class?

//TODO: discuss the fact that we're apparently going backwards from
// where we went in chapter 3, moving from domain objects as the service-layer api

* services and event handlers are quite similar.   They have dependencies
  on the UoW and other external adapters, and they even sometimes call each
  other.  More fundamentally, they're both ways of reacting to some sort of
  command or event, whether it's internal or external.


Let's see what would happen if we pushed the event-driven metaphor a little
further, and made all the services into event handlers too.  Event classes
will solve the "primitive obsession" problems, and the message bus will become
the core of our application:



[[full_messagebus]]
.The messagebus grows (src/allocation/messagebus.py)
====
[source,python]
----
HANDLERS = {
    events.BatchCreated: [handlers.add_batch],
    events.BatchQuantityChanged: [handlers.change_batch_quantity],
    events.AllocationRequest: [handlers.allocate],
    events.Deallocated: [handlers.allocate],
    events.OutOfStock: [handlers.send_out_of_stock_notification],
    events.Allocated: [handlers.publish_allocated_event],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====


////
TODO (ej) 

* I follow what's going on at a high level, but am getting lost in the weeds
due to the way some things are named and concepts are used. Some of the events
are implicitly named like commands instead of events, which is making it hard to
keep track. 

* The combination of type-hints+duck-typing, and treatment of AllocationRequest vs. 
Deallocated is a confusing, because there is only an
allocate(event: AllocationRequest,...) and no allocate(event:Deallocated).

* The naming of some things looks backwards.  For example,
  `BatchCreated` triggers `add_batch`, `BatchQuantityChanged` triggers
  `change_batch_quantity`, etc.  

  But then `AllocationRequest` triggers `allocate, and I'm unsure why
  it's not called `AllocationRequested`. Similarly, `BatchAdditionRequested`, 
  instead of `BatchCreated` would make be more intuitive. 

  And maybe something like `BatchQuantityChanged` -> handlers.update_batch_quantity,
  would be more clear `BatchQuantityChanged` -> handlers.change_batch_quantity

////

We define a series of new events, which capture the inputs, outputs, and
internal message structures of our system in a single place:

// TODO (DS): This is cool...but i can't help wishing you just started part 2
// with this pattern...

[[new_events]]
.More events (src/allocation/events.py)
====
[source,python]
----
@dataclass
class AllocationRequest(Event):
    orderid: str
    sku: str
    qty: int

#...

@dataclass
class BatchCreated(Event):
    ref: str
    sku: str
    qty: int
    eta: Optional[date] = None

@dataclass
class BatchQuantityChanged(Event):
    ref: str
    qty: int
----
====


And we combine our services and handlers into a single file,
_handlers.py_:


[[handlers_dot_py]]
.Handlers and services are the same thing, really (src/allocation/handlers.py)
====
[source,python]
----
def add_batch(
        event: events.BatchCreated, uow: unit_of_work.AbstractUnitOfWork
):
...
def change_batch_quantity(
        event: events.BatchQuantityChanged, uow: unit_of_work.AbstractUnitOfWork
):
...
def allocate(
        event: events.AllocationRequest, uow: unit_of_work.AbstractUnitOfWork
) -> str:
...
def send_out_of_stock_notification(
        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork,
):
...
def publish_allocated_event(
        event: events.Allocated, uow: unit_of_work.AbstractUnitOfWork,
):
----
====


Now the places in our code where we need to parse external input have a clearly
defined data structure for making requests into the system, the events, and a
single entrypoint into the system, the message bus:

////
TODO:
By the time we hit Example 17. Flask creates events and puts them on the messagebus. (src/allocation/flask_app.py), it would be nice to have a formal definition of the messagebus.handle function.
My guess is that it's just a simple loop mapping an event type to a handler using the HANDLERS dictionary, but explicitly stating that would be helpful.

https://github.com/python-leap/book/issues/37
////

[[flask_with_events]]
.Flask creates events and puts them on the messagebus. (src/allocation/flask_app.py)
====
[source,python]
----
@app.route("/add_batch", methods=['POST'])
def add_batch():
    eta = request.json['eta']
    if eta is not None:
        eta = datetime.fromisoformat(eta).date()
    event = events.BatchCreated(
        request.json['ref'], request.json['sku'], request.json['qty'], eta,
    )
    messagebus.handle([event], unit_of_work.SqlAlchemyUnitOfWork())
    return 'OK', 201

...

@app.route("/allocate", methods=['POST'])
def allocate_endpoint():
    try:
        event = events.AllocationRequest(
            request.json['orderid'], request.json['sku'], request.json['qty'],
        )
        ...
----
====


Redis now looks very similar

[[redis_with_events]]
.And so does redis (src/allocation/redis_pubsub.py)
====
[source,python]
----
def handle_change_batch_quantity(m):
    logging.debug('handling %s', m)
    data = json.loads(m['data'])
    event = events.BatchQuantityChanged(ref=data['batchref'], qty=data['qty'])
    messagebus.handle([event], uow=unit_of_work.SqlAlchemyUnitOfWork())
----
====

And our system is now entirely event-driven.

TIP: External events are one of the places it's important to apply some validation.
    See <<appendix_validation>> for some validation philosophy and examples.


.Internal vs External Events
*******************************************************************************
It's a good idea to keep the distinction between internal and external events
clear.  Some events may come from the outside, and some events may get upgraded
and published externally, but not all of them.  This is particularly important
if you get into [event sourcing](https://io.made.com/eventsourcing-101/) (very
much a topic for another book though).

*******************************************************************************


TODO: talk about the fact that we've implemented quite a complicated use case
    (change quantity, deallocate, start new transaction, reallocate,
    publish external notification), but thanks to our architecture the
    _complexity_ stays constant.  we just have events, handlers, and a unit
    of work.  it's easy to reason about, and easy to explain.  Possibly
    show a hacky version for comparison?


=== Why Have We Achieved?

=== What Have We Achieved?

* events are simple dataclasses that define the data structures for inputs,
  outputs, and internal messages within our system.  this is quite powerful
  from a DDD standpoint, since events often translate really well into
  business language; cf. "event storming" (TODO: link)

* handlers are the way we react to events.   They can call down to our
  model, or they can call out to external services.  We can define multiple
  handlers for a single event if we want to.  handlers can also raise other
  events.  This allows us to be very granular about what a handler does,
  and really stick to the SRP.

* events can come _from_ the outside, but they can also be published
  externally -- our `publish` handler converts an event to a message
  on a redis channel. We use events to talk to the outside world.

We've added bit of complexity to our architecture, but hopefully you can
see how we've now made it very easy to plug in almost any new requirement
from the business, whether it's a new use case, a new integration with
one of our internal systems, or an integration with external systems.

// TODO (DS): This whole chapter feels a little backwards... Why not start with
// what we're trying to achieve, discuss event architecture as a general
// approach, then show how it can be done in python.
