  [[chapter_09_commands]]
== Commands and Command Handler

//TODO get rid of bullets

.In this chapter
********************************************************************************

* We'll discuss the difference between _events_ and _commands_.
* We'll extend our message bus to handle command messages.
* We'll finish rebuilding our application as a message-processor.

  // DIAGRAM GOES HERE

********************************************************************************

In the previous chapter we talked about using events as a way of representing
the inputs to our system. This starts to turn our application into a message
processing machine.

TODO: DIAGRAM: Message processor

To achieve that, we converted all our use-case functions to event-handlers.
When the API receives a POST to create a new batch, it builds a new `BatchCreated`
event and handles it as though it came from an external system.
This might have felt counter-intuitive. After all, the batch _hasn't_ been
created yet, that's why we called the API. We're going to fix that conceptual
wart by introducing _Commands_.

=== Commands and Events

Like events, commands are a type of message - instructions sent by one part of
a system to another. Like events, we usually represent commands with dumb data
structures and we can handle them in much the same way.

The differences between them, though, are important.

Commands are sent by one actor to another specific actor with the expectation that
a particular thing will happen as a result. When I post a form to an API handler,
I am sending a command. We name commands with imperative tense verb phrases like
"allocate stock," or "delay shipment."

Commands capture _intent_. They express our wish for the system to do something.
As a result, when they fail, the sender needs to receive error information.

Events are broadcast by an actor to all interested listeners. When we publish the
`batch_quantity_changed` we don't know who's going to pick it up. We name events
with past-tense verb phrases like "order allocated to stock," or "shipment delayed."

We often use events to spread the knowledge about successful commands.

Events capture _facts_ about things that happened in the past. Since we don't
know who's handling an event, senders should not care whether the receivers
succeeded or failed.

[cols="e,a,a", frame="none"]
.Events vs Commands
|===
e|      e| Event e| Command
| Named | Past-Tense | Imperative Tense
| Error Handling | Fail independently | Fail noisily
| Sent to | All listeners | One recipient
|===


// TODO: Diagram of user "buy stock" -> "stock purchased"
//                       "create batch" -> "batch created"


What kinds of commands do we have in our system right now? 

[[commands_dot_py]]
.Pulling out some commands (src/allocation/commands.py)
====
[source,python]
----
class Command:
    pass

@dataclass
class Allocate(Command):  #<1>
    orderid: str
    sku: str
    qty: int

@dataclass
class CreateBatch(Command):  #<2>
    ref: str
    sku: str
    qty: int
    eta: Optional[date] = None

@dataclass
class ChangeBatchQuantity(Command):  #<3>
    ref: str
    qty: int
----
====

<1> `commands.Allocate` will replace `events.AllocationRequired`
<2> `commands.CreateBatch` will replace `events.BatchCreated`
<3> `commands.ChangeBatchQuantity` will replace `events.BatchQuantityChanged``

Each of the use-cases that we discussed earlier in the book is really a command,
an instruction for the system to try and do a thing. To unify the two halves of
the domain, we're going to make a simple change: instead of directly invoking
our use case functions, like we did before, we're going to take these
commands, and we're going to put them on the message bus. As a result, our
message bus changes somewhat.

[[new_messagebus]]
.Messagebus handles events and commands differently (src/allocation/messagebus.py)
====
[source,python]
----
Message = Union[commands.Command, events.Event]


def handle(message: Message, uow: unit_of_work.AbstractUnitOfWork):  #<1>
    if isinstance(message, events.Event):
        handle_event(message, uow)
    elif isinstance(message, commands.Command):
        return handle_command(message, uow)
    else:
        raise Exception(f'{message} was not an Event or Command')


def handle_event(event: events.Event, uow: unit_of_work.AbstractUnitOfWork):  #<2>
    for handler in EVENT_HANDLERS[type(event)]:
        try:
            print('handling event', event, 'with handler', handler, flush=True)
            handler(event, uow=uow)
        except:  #<2>
            print(f'Exception handling event {event}\n:{traceback.format_exc()}')
            continue


def handle_command(command, uow: unit_of_work.AbstractUnitOfWork):  #<3>
    print('handling command', command, flush=True)
    try:
        handler = COMMAND_HANDLERS[type(command)]
        return handler(command, uow=uow)
    except Exception as e:
        print(f'Exception handling command {command}: {e}')
        raise e  #<3>


EVENT_HANDLERS = {
    events.OutOfStock: [handlers.send_out_of_stock_notification],
}  # type: Dict[Type[events.Event], List[Callable]]  #<2>

COMMAND_HANDLERS = {
    commands.Allocate: handlers.allocate,
    commands.CreateBatch: handlers.add_batch,
    commands.ChangeBatchQuantity: handlers.change_batch_quantity,
}  # type: Dict[Type[commands.Command], Callable]  #<3>
----
====


<1> It still has a main `handle()` entrypoint, that takes a list of messages,
    that may be commands or events.

<2> We dispatch to a function for handling events.  It can delegate to multiple
    handlers per event, and it catches and logs any errors, but does not let them
    interrupt message processing.

<3> The command handler expects just one handler per command.  If any errors
    are raised, they fail hard and will bubble up.




Why does `handle_command` have a `return`, but `handle_events` doesn't, we hear
you ask?  It's so that we can return the batchref from the API.  

[[flask_uses_command]]
.Flask gets a response from the command handler (src/allocation/flask_app.py)
====
[source,python]
----
@app.route("/allocate", methods=['POST'])
def allocate_endpoint():
    try:
        cmd = commands.Allocate(
            request.json['orderid'], request.json['sku'], request.json['qty'],
        )
        uow = unit_of_work.SqlAlchemyUnitOfWork()
        batchref = messagebus.handle(cmd, uow)
    except exceptions.InvalidSku as e:
        return jsonify({'message': str(e)}), 400

    return jsonify({'batchref': batchref}), 201
----
====

It's the same wart we've drawn attention to before.  In <<chapter_11_cqrs>>
we'll look at a way of separating out command handling from read requests.

////
TODO (ej) Devil's advocate:  If your messagebus.handle processes half the events
     in the list, then drops the rest on the floor due to a db network outage
     or being OOM killed, how do you mitigate problems cause by the lost messages?
////

TODO: discussion, can events raise commands?
=== Events, Commands, and Error Handling

Many developers get uncomfortable at this point, and ask "what happens when an
event fails to process. How am I supposed to make sure the system is in a
consistent state?"

If we manage to process half of the events during `messagebus.handle` before an
out-of-memory error kills our process, how do we mitigate problems caused by the
lost messages?

Let's start with the worst case: we fail to handle and event, and the system is
left in an inconsistent state. What kind of error would cause this? Often in our
systems we can end up in an inconsistent state when only half an operation is
completed.

For example, we could allocate 3 units of DESIRABLE_BEANBAG to a customer's
order but somehow fail to reduce the amount of remaining stock. This would
cause an inconsistent state: the 3 units of stock are both allocated and
available depending on how you look at it. Later on, we might allocate those
same beanbags to another customer, causing a headache for customer support.

In our allocation service, though, we've already taken steps to prevent that
happening. We've carefully identified _Aggregates_ which act as consistency
boundaries, and we've introduced a _Unit of Work_ that manages the atomic
success or failure of an update to an aggregate.

For example, when we allocate stock to an order, our consistency boundary is the
Product aggregate. This means that we can't accidentally over-allocate: either
a particular order line is allocated to the product, or it is not - there's no
room for inconsistent states.

By definition, we don't require two aggregates to be immediately consistent, so
if we fail to process an event, and only update a single aggregate, our system
can still be made eventually consistent. We shouldn't violate any constraints of
the system.

With this example in mind, we can better understand the reason for splitting
messages into Commands and Events: When a user wants to make the system do
something, we represent their request as a _Command_. That command should modify
a single _Aggregate_ and either succeed or fail in totality. Any other book
keeping, clean up, and notification we need to do can happen via an _Event_. We
don't require the event handlers to succeed in order for the command to be
successful.

Let's take another example to see why not.

Imagine we are building an e-commerce website that sells expensive luxury goods.
Our marketing department want to reward customers for repeat visits. We will
flag customers as VIPs once they make their third purchase, and this will
entitle them to priority treatment and special offers. Our acceptance criteria
for this story read as follows:

Given a customer with two orders in their history,
when the customer places a third order,
they should be flagged as a VIP.

When a customer first becomes a VIP
we should send them an email to congratulate them

Using the techniques we've already discussed in this book, we decide that we
want to build a new History aggregate that records orders and can raise domain
events when rules are met. We will structure the code like this:

[[new_messagebus]]
.VIP Customer
====
[source,python]
----

class History (Aggregate):

    def __init__(self, customer_id: int):
        self.orders = Set() # Set[HistoryEntry]
        self.customer_id = customer_id

    def record_order(self, order_id: str, order_amount: int): #<1>
        entry = HistoryEntry(order_id, order_amount)

        if entry in self.orders:
            return

        self.orders.add(entry)

        if len(self.orders) == 3:
            self.events.append(
                CustomerBecameVIP(self.customer_id)
            )


def create_order_from_basket(uow, cmd: CreateOrder): #<2>
    with uow:
        order = Order.from_basket(cmd.customer_id, cmd.basket)
        uow.orders.add(
        uow.commit() # raises OrderCreated


def update_customer_history(uow, event: OrderCreated): #<3>
    with uow:
        history = uow.order_history.get(event.customer_id)
        history.record_order(event.order_id, event.order_amount)
        uow.commit() # raises CustomerBecameVIP


def congratulate_vip_customer(uow, event: CustomerBecameVip): #<4>
    with uow:
        customer = uow.customers.get(event.customer_id)
        email.send(
            customer.email_address,
            f'Congratulations {customer.first_name}!'
        )
        
----
====

<1> The History aggregate captures the rules for when a customer becomes a VIP.
<2> Our first handler creates an order for the customer and raises a domain
    event 'OrderCreated'.
<3> Our second handler updates the History object to record that an order was
    created.
<4> Finally we send an email to the customer when they become a VIP using the
    same email system we used for the OutOfStock event.

//TODO: Sequence diagram here?

Using this code we can gain some intuition about error handling in an
event-driven system.

In our current implementation, we raise events about an aggregate _after_ we
persist our state to the database. What if we raised those events _before_ we
persisted, and committed all our changes at the same time? That way we could be
sure that all the work was complete. Wouldn't that be safer?

What happens, though if the email server is slightly overloaded? If all the work
has to complete at the same time, a busy email server can stop us taking money
for orders.

What happens if there is a bug in the implementation of the History aggregate?
Should we fail to take your money just because we can't recognise you as a VIP?

By separating these concerns out, we have made it possible for things to fail
in isolation, which improves the overall reliability of the system. The only
part of this code that *has* to complete is the Command Handler that creates an
order. This is the only part that a customer cares about, and it's the part that
our business stakeholders should prioritise.

* Recovering from logs
* Using a job queue