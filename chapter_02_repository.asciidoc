[[chapter_02]]
== Repository Pattern

We expect to be working in an agile manner, so our priority is to get to an MVP
as quickly as possible.  Once we've identified the first use case we want to
support and we've built a service in the domain for it (the `allocate()` function),
we want to start thinking about exposing it to users as quickly as possible.

In our case that's going to be a web API, and there's a good case for saying that,
in a real project, you might dive straight in with some end-to-end tests and
start plugging in a web framework, test-driving things outside-in.

But we know that, no matter what, we're going to need some form of persistent
storage, and this is a textbook, so we can allow ourselves a tiny bit more
bottom-up development, and start to think about storage and databases.


=== Some pseudocode: what are we going to need?

When we build our first API endpoint, we know we're going to have
some code that looks more or less like <<api_endpoint_pseudocode>>:


[[api_endpoint_pseudocode]]
.What our first API endpoint will look like
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    order = # ... fetch order from db, or maybe 
            # just instantiate it from request params
    warehouse = # ... retrieve warehouse from db
    shipments = # ... load all shipments from
    new_allocation = allocate(order, warehouse, shipments)
    # .. and then save the allocation back to the database somehow
    return 201
----
====

We'll need a way to retrieve warehouse, shipment and order info
from the DB and instantiate our domain model objects from them,
and we'll also need a way of saving them back to the database.



=== Applying the Dependency Inversion Principle to the Database

We're all reasonably familiar with the best practice for a system
with a UI, some logic, and a database:  the "layered architecture".


[[layered_architecture]]
.Layered Architecture
====
[role="skip"]
[source,text]
----
+------------------------------------------------------------+
|                  Presentation Layer                        |
+------------------------------------------------------------+
                          |
                          V
+------------------------------------------------------------+
|                   Business Logic                           |
+------------------------------------------------------------+
                          |
                          V
+------------------------------------------------------------+
|                    Database Layer                          |
+------------------------------------------------------------+
----
====

You might think of it as Model-View-Controller, and have more layers, but the
essential principle is to keep the layers separate (which is a good thing), and
to have each layer depend only on the one below...

But we want our domain model to have _no dependencies whatsoever_. We don't
want infrastructure concerns bleeding over into our domain model and slowing
down our unit tests or our ability to make changes.

Instead, as discussed in the prologue, we'll think of our model as being on the
"inside", and dependencies flowing inwards to it;  what people sometimes call
"ports and adapters".


.Is this Ports and Adapters?
*******************************************************************************
> "Is this Ports and Adapters?  Or is it hexagonal architecture?  Is it the same
> as the Onion architecture?  What about the Clean architecture?  What's a Port
> and what's an Adapter?  Why do you people have so many words for the same thing?

...we hear you ask.  The answer to all these questions is yes, pretty much. Well,
apart from the what-is-a-port-and-what-is-an-adapter question, which we'll
come back to later, but the short answer to that one is that it doesn't really
matter.

Although some people like to nitpick over the differences, all these are
pretty much names for the same thing, and they all boil down to the
Dependency Inversion Principle--high-level modules (the domain) should
not depend on low-level ones (the infrastructure).

We'll get into some of the nitty-gritty around "depending on abstractions",
and whether there is a Pythonic equivalent of interfaces, later in the book.
*******************************************************************************

==== The "normal" ORM way: model depends on ORM.

How to implement it when we want to use a tool like an ORM though? We don't
want to be hand-coding SQL (at least, not yet!).  But if you follow the typical
SQLAlchemy tutorial, you'll end up with something like this:


[[typical_sqlalchemy_example]]
.SQLAlchemy "declarative" syntax, model depends on ORM (orm.py)
====
[role="skip"]
[source,python]
----
from sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Order(Base):
    id = Column(Integer, primary_key=True)

class OrderLine(Base):
    id = Column(Integer, primary_key=True)
    sku = Column(String(250))
    qty = Integer(String(250))
    order_id = Column(Integer, ForeignKey('order.id'))
    order = relationship(Order)

class Allocation(Base):
    #... and so on
----
====

....And our pristine model is now full of dependencies on the ORM, and is
starting to look ugly as hell.



==== Inverting the dependency: ORM depends on model.

But that's not the only way to use SQLAlchemy.  The alternative is to define
your schema separately, and an explicit _mapper_ for how to convert between the
schema and our domain model:

https://docs.sqlalchemy.org/en/latest/orm/mapping_styles.html#classical-mappings

//TODO: test this listing using an intermediary tag.

[[sqlalchemy_classical_mapper]]
.Explicit ORM Mapping with SQLALchemy Table objects (orm.py)
====
[role="skip"]
[source,python]
----
from sqlalchemy import Table, MetaData, Column, Integer, String, ForeignKey, Date
from sqlalchemy.orm import mapper, relationship

import domain_model  #<1>


metadata = MetaData()

order = Table(  #<2>
    'order', metadata,
    Column('reference', String(255), primary_key=True),
)

order_lines = Table(  #<2>
    'order_lines', metadata,
    Column('order_reference', ForeignKey('order.reference'), primary_key=True),
    Column('sku', String(255), primary_key=True),
    Column('qty', Integer),
)
#...


def start_mappers():
    mapper(Line, order_lines)  #<3>
    mapper(Order, order, properties={  #<3>
        'lines': relationship(Order.Line, cascade="all, delete-orphan")
    })
    #...
----
====

<1> The ORM imports the domain model, and not the other way around

<2> We define our database tables and columns using SQLAlchemy's Pythonic DDL.

<3> And when we call the `mapper` function, SqlAlchemy binds our domain model
    classes to the various tables we've defined.

This gives us all the benefits of SQLAlchemy, including the ability to use
`alembic` for migrations, and the ability to transparently query using our
domain classes, as we'll see.

When you're first trying to build your ORM config, it can be useful to write
some tests for it, as in <<orm_tests>>:


[[orm_tests]]
.Testing the ORM directly (throwaway tests) (test_orm.py)
====
[source,python]
[role="skip"]
----
def test_order_mapper_can_load_lines(session):
    session.execute('INSERT INTO "order" VALUES (1)')
    session.execute('INSERT INTO "order" VALUES (2)')
    session.execute('INSERT INTO "order_lines" VALUES (1, "sku1", 12)')
    session.execute('INSERT INTO "order_lines" VALUES (1, "sku2", 13)')
    session.execute('INSERT INTO "order_lines" VALUES (2, "sku3", 14)')
    expected_order = Order({'sku1': 12, 'sku2': 13})
    retrieved_order = session.query(Order).first()
    assert retrieved_order.lines == expected_order.lines


def test_order_mapper_can_save_lines(session):
    new_order = Order({'sku1': 12, 'sku2': 13})
    session.add(new_order)
    session.commit()

    rows = list(session.execute('SELECT * FROM "order_lines"'))
    assert rows == [
        (1, 'sku1', 12),
        (1, 'sku2', 13),
    ]
----
====

But you probably wouldn't keep these tests around--as we'll see shortly, once
you've taken the step of inverting the dependency of ORM and domain model, it's
only a small additional step to implement an additional abstraction called the
Repository pattern, which will be easier to write tests against, and will
provide a simple, common interface for faking out later in tests.

But we've already achieved our objective of inverting the traditional
dependency: the domain model stays "pure" and free from infrastructure
concerns.  We could throw away SQLAlchemy and use a different ORM, or a totally
different persistence system, and the domain model doesn't need to change at
all.

We are glossing over some complexity here.  If we want to stick to using dicts
as our primary data structure, there is some slightly tricky config to get
right.  For the curious, there's more example code at
https://github.com/python-leap/code/blob/orm-experiments-backtodicts/orm.py

//TODO: fix link.

Depending on what you're doing in your domain model, and especially if you
stray far from the OO paradigm, you may find it increasingly hard to get the
ORM to produce the exact behaviour you need,  and you may need to modify your
domain modelfootnote:[Harry came extremely close to giving up his beloved
dicts, but thanks to the amazingly helpful SQLAlchemy maintainers, he didn't
have to, or at least not yet.  Shout out to Mike Bayer!].  As so often with
architectural decisions, there is a trade-off you'll need to consider.  As the
Zen of Python says, "Practicality beats purity!"

At this point though, our flask API endpoint might look something like
<<api_endpoint_with_session>>, and we could get it to work just fine.

[[api_endpoint_with_session]]
.Using SQLAlchemy directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    order = Order(request.params['order_id'], request.params['lines'])
    warehouse = session.query(Warehouse).one()
    shipments = session.query(Shipment).all()
    new_allocation = allocate(order, warehouse, shipments)
    session.add(new_allocation)
    session.commit()
    return 201
----
====

=== Introducing Repository Pattern.

The repository pattern is an abstraction over persistent storage. It hides the
boring details of data access by pretending that our database is really an
in-memory data structure with semantics similar to a set or dict.

The ideal repository has just two methods: `add` to put a new item in the
repository, and `get` to return a previously added item. We stick rigidly to
using these methods for data access in our domain and our _service layer_. This
self-imposed simplicity stops us from coupling our domain model to the database.

Whenever we introduce an architectural pattern in this book, we'll always be
trying to ask: "what do we get for this?  And what does it cost us?". Rich
Hickey once said "programmers know the benefits of everything and the tradeoffs
of nothing".

Usually at the very least we'll be introducing an extra layer of abstraction,
and although we may hope it will be reducing complexity overall, it does add
complexity locally, and it has a cost in terms raw numbers of moving parts and
ongoing maintenance.

Repository pattern is probably one of the easiest choices in the book though,
if you've already heading down the DDD and dependency inversion route.  As far
as our code is concerned, we're really just swapping the SQLAlchemy abstraction
(`session.query(Shipment)`) for a different one (`shipments_repo.get`) which we
designed.

We will have to write a few lines of code in our repository class each time we
add a new domain object that we want to retrieve, but in return we get a very
simple abstraction over our storage layer, which we control, which would make
it very easy to make fundamental changes to the way we store things later, and
which as we'll see is very easy to fake out for unit tests.

In addition, "Repository pattern" is so common in the DDD world that, if you
do collaborate with programmers that have come to Python from the Java and C#
worlds, they're likely to recognise it.

As always we start with a test.  Unlike the ORM tests from earlier, these tests
are good candidates for staying part of your codebase longer term, particularly
if any parts of your domain model mean the object-relational map is nontrivial.


[[repo_test_save]]
.Repository test for saving an object (test_repository.py)
====
[source,python]
----
def test_repository_can_save_an_order_to_the_database(session):
    order = Order("orderref", {'sku1': 12, 'sku2': 13})

    repo = repository.OrderRepository(session)
    repo.add(order)
    session.commit()

    rows = list(session.execute('SELECT * FROM "order_lines"'))
    assert rows == [
        (order.reference, 'sku1', 12),
        (order.reference, 'sku2', 13),
    ]
----
====



[[repo_test_retrieve]]
.Repository test for retrieving an object (test_repository.py)
====
[source,python]
----
def test_repository_can_get_an_existing_order(session):
    session.execute('INSERT INTO "order" VALUES ("ref1")')
    session.execute('INSERT INTO "order" VALUES ("ref2")')
    session.execute('INSERT INTO "order_lines" VALUES ("ref1", "sku1", 12)')
    session.execute('INSERT INTO "order_lines" VALUES ("ref2", "sku2", 13)')
    session.execute('INSERT INTO "order_lines" VALUES ("ref2", "sku3", 14)')

    repo = repository.OrderRepository(session)
    retrieved_order = repo.get("ref2")

    expected_order = Order('ref2', {'sku2': 13, 'sku3': 14})
    assert retrieved_order._lines == expected_order._lines
----
====


[[repo_test_update]]
.Repository test for updating an object (test_repository.py)
====
[source,python]
----
def test_repository_can_modify_an_existing_order(session):
    session.execute('INSERT INTO "order" VALUES ("r1")')
    session.execute('INSERT INTO "order_lines" VALUES ("r1", "oldsku1", 12)')
    session.execute('INSERT INTO "order_lines" VALUES ("r1", "oldsku2", 12)')

    repo = repository.OrderRepository(session)
    order = repo.get("r1")
    order['oldsku2'] = 100
    order['newsku'] = 14
    session.commit()  #TODO: does this belong in repository?

    rows = list(session.execute('SELECT * FROM "order_lines"'))
    assert rows == [
        (order.reference, 'oldsku1', 12),
        (order.reference, 'oldsku2', 100),
        (order.reference, 'newsku', 14),
    ]
----
====


Whether or not you painstakingly write tests for every model is
a judgement call.  Once you have one class tested for create/modify/save,
you might be happy to go on and do the others with a minimal roundtrip
test, or even nothing at all, if they all follow a similar pattern.


You end up with something like <<simple_model_repositories>>:


[[simple_model_repositories]]
.Many repositories look similar (repository.py)
====
[source,python]
----
class _ModelRepository:
    def __init__(self, model_class, session):
        self._model_class = model_class
        self.session = session

    def get(self, reference):
        return self.session.query(self._model_class).filter_by(
            reference=reference
        ).one()

    def add(self, obj):
        assert isinstance(obj, self._model_class)
        self.session.add(obj)


OrderRepository = lambda s: _ModelRepository(domain_model.Order, s)
ShipmentRepository = lambda s: _ModelRepository(domain_model.Shipment, s)
AllocationRepository = lambda s: _ModelRepository(domain_model.Allocation, s)
----
====

TODO: add `.list()` option to shipments repository?

Because our warehouse is a sort of global singleton, it gets treated
slightly differently:

[[warehouse_repository]]
.Although there are some special-cases (repository.py)
====
[source,python]
----
class WarehouseRepository:
    def __init__(self, session):
        self.session = session

    def get(self):
        wh = self.session.query(domain_model.Warehouse).one()
        assert wh.reference == 'warehouse'
        return wh

    def add(self, warehouse):
        warehouse.reference = 'warehouse'
        self.session.add(warehouse)
----
====

And now our flask endpoint might look something like <<api_endpoint_with_repo>>:

[[api_endpoint_with_repo]]
.Using our repository directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    order = Order(request.params['order_id'], request.params['lines'])
    warehouse = warehouse_repo.get()
    shipments = shipment_repo.list()
    new_allocation = allocate(order, warehouse, shipments)
    allocation_repo.add(new_allocation)
    session.commit()  # TODO: still need to fix this
    return 201
----
====

=== Building a fake repository for tests is now trivial!

Here's one of the biggest benefits of Repository pattern.


[[fake_repository]]
.A simple fake repository subclassing set (repository.py)
====
[source,python]
----
class FakeRepository(set):

    def get(self, reference):
        return next(obj for obj in self if obj.reference == reference)
----
====

Because we subclass `set` we get the `.add()` method for free, and
`.get()` is a one-liner.

Using a fake repo in tests is really easy, and we have a simple
abstraction that's easy to use and reason about:

[[fake_repository_example]]
.Example usage of fake repository (test_api.py)
====
[role="skip"]
[source,python]
----
fake_repo = FakeRepository([shipment1, shipment2, shipment3])
----
====


How do we actually instantiate these repositories, fake or real?
What will our flask app actually look like?  Find out in the next
exciting instalment...


