[[chapter_02_repository]]
== Repository Pattern

In the previous chapter we built a simple domain model that can allocate orders
to batches of stock. It's easy for us to write tests against this code because
there aren't any dependencies or infrastructure to set up. If we needed to run
a database or an API and create test data, our tests would be harder to write
and maintain.

Sadly, at some point we'll need to put our perfect little model in the hands of
users and we'll need to contend with the real world of spreadsheets and web
browsers and race conditions. For the next few chapters we're going to look at
how we can connect our idealised domain model to external state.

We expect to be working in an agile manner, so our priority is to get to an MVP
as quickly as possible.  In our case that's going to be a web API. In a real
project, you might dive straight in with some end-to-end tests and start
plugging in a web framework, test-driving things outside-in.

But we know that, no matter what, we're going to need some form of persistent
storage, and this is a textbook, so we can allow ourselves a tiny bit more
bottom-up development, and start to think about storage and databases.


=== Some pseudocode: what are we going to need?

When we build our first API endpoint, we know we're going to have
some code that looks more or less like <<api_endpoint_pseudocode>>:


[[api_endpoint_pseudocode]]
.What our first API endpoint will look like
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    order_lines = # ... fetch from db, or maybe just 
                  # instantiate them from request params
    batches = # ... load all batches from db
    for line in order.lines:
        allocate(line, batches)
    # .. and then save the allocation back to the database somehow
    return 201
----
====

We'll need a way to retrieve batch info from the DB and instantiate our domain
model objects from it, and we'll also need a way of saving them back to the
database.


=== Applying the Dependency Inversion Principle to the Database

We're all reasonably familiar with the best practice for a system
with a UI, some logic, and a database:  the "layered architecture".


[[layered_architecture2]]
.Layered Architecture
====
[role="skip"]
[source,text]
----
+------------------------------------------------------------+
|                  Presentation Layer                        |
+------------------------------------------------------------+
                          |
                          V
+------------------------------------------------------------+
|                   Business Logic                           |
+------------------------------------------------------------+
                          |
                          V
+------------------------------------------------------------+
|                    Database Layer                          |
+------------------------------------------------------------+
----
====

You might think of it as Model-View-Controller, and have more layers, but the
essential principle is to keep the layers separate (which is a good thing), and
to have each layer depend only on the one below...

But we want our domain model to have _no dependencies whatsoever_. We don't
want infrastructure concerns bleeding over into our domain model and slowing
down our unit tests or our ability to make changes.

Instead, as discussed in the prologue, we'll think of our model as being on the
"inside", and dependencies flowing inwards to it;  what people sometimes call
"ports and adapters".


.Is this Ports and Adapters?
*******************************************************************************
> "Is this Ports and Adapters?  Or is it hexagonal architecture?  Is it the same
> as the Onion architecture?  What about the Clean architecture?  What's a Port
> and what's an Adapter?  Why do you people have so many words for the same thing?

Although some people like to nitpick over the differences, all these are
pretty much names for the same thing, and they all boil down to the
Dependency Inversion Principle--high-level modules (the domain) should
not depend on low-level ones (the infrastructure).

We'll get into some of the nitty-gritty around "depending on abstractions",
and whether there is a Pythonic equivalent of interfaces, later in the book.
*******************************************************************************

==== The "normal" ORM way: model depends on ORM.

In 2019 it's unlikely that your team are hand-rolling their own SQL queries.
Instead, you're almost certainly using some kind of framework to generate
SQL for you based on your model objects.

These frameworks are called Object-Relational Mappers because they exist to
bridge the conceptual gap between the world of objects and domain modelling, and
the world of databases and relational algebra.

The most important thing an ORM gives us is "persistence ignorance": the idea
that our fancy domain model doesn't need to know anything about how data are
loaded or persisted. This helps to keep our domain clean of dependencies.

But if you follow the typical SQLAlchemy tutorial, you'll end up with something
like this:


[[typical_sqlalchemy_example]]
.SQLAlchemy "declarative" syntax, model depends on ORM (orm.py)
====
[role="skip"]
[source,python]
----
from sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Order(Base):
    id = Column(Integer, primary_key=True)

class OrderLine(Base):
    id = Column(Integer, primary_key=True)
    sku = Column(String(250))
    qty = Integer(String(250))
    order_id = Column(Integer, ForeignKey('order.id'))
    order = relationship(Order)

class Allocation(Base):
    #... and so on
----
====

...And our pristine model is now full of dependencies on the ORM, and is
starting to look ugly as hell. Can we really say this model is ignorant
of the database? How can it be separate from storage concerns when our model
properties are directly coupled to database columns?


==== Inverting the dependency: ORM depends on model.

Well, thankfully, that's not the only way to use SQLAlchemy.  The alternative is
to define your schema separately, and an explicit _mapper_ for how to convert
between the schema and our domain model:

https://docs.sqlalchemy.org/en/latest/orm/mapping_styles.html#classical-mappings


[[sqlalchemy_classical_mapper]]
.Explicit ORM Mapping with SQLALchemy Table objects (orm.py)
====
[source,python]
----
from sqlalchemy.orm import mapper, relationship

import model  #<1>


metadata = MetaData()

order_lines = Table(  #<2>
    'order_lines', metadata,
    Column('id', Integer, primary_key=True, autoincrement=True),
    Column('orderid', String(255)),
    Column('sku', String(255)),
    Column('qty', Integer, nullable=False),
)
#...


def start_mappers():
    lines_mapper = mapper(model.OrderLine, order_lines)  #<3>
----
====



<1> The ORM imports the domain model, and not the other way around

<2> We define our database tables and columns using SQLAlchemy's Pythonic DDL.

<3> And when we call the `mapper` function, SqlAlchemy binds our domain model
    classes to the various tables we've defined.

This gives us all the benefits of SQLAlchemy, including the ability to use
`alembic` for migrations, and the ability to transparently query using our
domain classes, as we'll see.

// TODO: mention hack: `@dataclass(frozen=True)` -> `dataclass(unsafe_hash=True)`

When you're first trying to build your ORM config, it can be useful to write
some tests for it, as in <<orm_tests>>:


[[orm_tests]]
.Testing the ORM directly (throwaway tests) (test_orm.py)
====
[source,python]
----
def test_orderline_mapper_can_load_lines(session):
    session.execute(
        'INSERT INTO order_lines (orderid, sku, qty) VALUES '
        '("order1", "sku1", 12),'
        '("order1", "sku2", 13),'
        '("order2", "sku3", 14)'
    )
    expected = [
        model.OrderLine('order1', 'sku1', 12),
        model.OrderLine('order1', 'sku2', 13),
        model.OrderLine('order2', 'sku3', 14),
    ]
    assert session.query(model.OrderLine).all() == expected


def test_orderline_mapper_can_save_lines(session):
    new_line = model.OrderLine('order1', 'sku1', 12)
    session.add(new_line)
    session.commit()

    rows = list(session.execute('SELECT orderid, sku, qty FROM "order_lines"'))
    assert rows == [('order1', 'sku1', 12)]
----
====


But you probably wouldn't keep these tests around--as we'll see shortly, once
you've taken the step of inverting the dependency of ORM and domain model, it's
only a small additional step to implement an additional abstraction called the
Repository pattern, which will be easier to write tests against, and will
provide a simple, common interface for faking out later in tests.

But we've already achieved our objective of inverting the traditional
dependency: the domain model stays "pure" and free from infrastructure
concerns.  We could throw away SQLAlchemy and use a different ORM, or a totally
different persistence system, and the domain model doesn't need to change at
all.


Depending on what you're doing in your domain model, and especially if you
stray far from the OO paradigm, you may find it increasingly hard to get the
ORM to produce the exact behaviour you need,  and you may need to modify your
domain modelfootnote:[Shout out to the amazingly helpful SQLAlchemy
maintainers, and Mike Bayer in particular].  As so often with
architectural decisions, there is a trade-off you'll need to consider.  As the
Zen of Python says, "Practicality beats purity!"

At this point though, our flask API endpoint might look something like
<<api_endpoint_with_session>>, and we could get it to work just fine.

[[api_endpoint_with_session]]
.Using SQLAlchemy directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    order = Order(request.params['order_id'], request.params['lines'])
    warehouse = session.query(Warehouse).one()
    shipments = session.query(Shipment).all()
    new_allocation = allocate(order, warehouse, shipments)
    session.add(new_allocation)
    session.commit()
    return 201
----
====

=== Introducing Repository Pattern.

The repository pattern is an abstraction over persistent storage. It hides the
boring details of data access by pretending that all of our data is in memory.

If we had infinite memory in our laptops, we'd have no need for clumsy databases.
Instead, we could just use our objects whenever we liked. What would that look
like?

[[all_my_data]]
.You've got to get your data from somewhere
====
[role="skip"]
[source,python]
----
import all_my_data from data

def create_a_batch(self):
    batch = Batch(...)
    all_my_data.batches.add(batch)

def modify_a_batch(self, batch_id, new_quantity):
    batch = all_my_data.batches.get(batch_id)
    batch.change_initial_quantity(new_quantity)

----
====


Even though our objects are in memory, we need to put them _somewhere_ so we can
find them again. Our in memory data would let us add new objects, just like a
list or a set, and since the objects are in memory we never need to call a
"Save" method, we just fetch the object we care about, and modify it in memory.

The ideal repository has just two methods: `add` to put a new item in the
repository, and `get` to return a previously added item. We stick rigidly to
using these methods for data access in our domain and our _service layer_. This
self-imposed simplicity stops us from coupling our domain model to the database.

Whenever we introduce an architectural pattern in this book, we'll always be
trying to ask: "what do we get for this?  And what does it cost us?". Rich
Hickey once said "programmers know the benefits of everything and the tradeoffs
of nothing".

Usually at the very least we'll be introducing an extra layer of abstraction,
and although we may hope it will be reducing complexity overall, it does add
complexity locally, and it has a cost in terms raw numbers of moving parts and
ongoing maintenance.

Repository pattern is probably one of the easiest choices in the book though,
if you've already heading down the DDD and dependency inversion route.  As far
as our code is concerned, we're really just swapping the SQLAlchemy abstraction
(`session.query(Shipment)`) for a different one (`shipments_repo.get`) which we
designed.

We will have to write a few lines of code in our repository class each time we
add a new domain object that we want to retrieve, but in return we get a very
simple abstraction over our storage layer, which we control, which would make
it very easy to make fundamental changes to the way we store things later, and
which as we'll see is very easy to fake out for unit tests.

In addition, "Repository pattern" is so common in the DDD world that, if you
do collaborate with programmers that have come to Python from the Java and C#
worlds, they're likely to recognise it.

As always we start with a test.  Unlike the ORM tests from earlier, these tests
are good candidates for staying part of your codebase longer term, particularly
if any parts of your domain model mean the object-relational map is nontrivial.


[[repo_test_save]]
.Repository test for saving an object (test_repository.py)
====
[source,python]
----
def test_repository_can_save_a_batch(session):
    batch = model.Batch('batch1', 'sku1', 100, eta=None)

    repo = repository.BatchRepository(session)
    repo.add(batch)
    session.commit()

    rows = list(session.execute(
        'SELECT reference, sku, _purchased_quantity, eta FROM "batches"')
    )
    assert rows == [('batch1', 'sku1', 100, None)]
----
====


The next test involves retrieving batches and allocations so it's more
complex:


[[repo_test_retrieve]]
.Repository test for retrieving a complex object (test_repository.py)
====
[source,python]
----
def test_repository_can_retrieve_a_batch_with_allocations(session):
    session.execute(
        'INSERT INTO order_lines (orderid, sku, qty) VALUES ("order1", "sku1", 12)'
    )
    [[olid]] = session.execute(
        'SELECT id FROM order_lines WHERE orderid=:orderid AND sku=:sku',
        dict(orderid='order1', sku='sku1')
    )
    session.execute(
        'INSERT INTO batches (reference, sku, _purchased_quantity, eta)'
        ' VALUES ("batch1", "sku1", 100, null)'
    )
    [[b1id]] = session.execute(
        'SELECT id FROM batches WHERE reference=:ref AND sku=:sku',
        dict(ref='batch1', sku='sku1')
    )
    session.execute(
        'INSERT INTO batches (reference, sku, _purchased_quantity, eta)'
        ' VALUES ("batch2", "sku1", 100, null)'
    )
    session.execute(
        'INSERT INTO allocations (orderline_id, batch_id) VALUES (:olid, :b1id)',
        dict(olid=olid, b1id=b1id)
    )

    repo = repository.BatchRepository(session)
    retrieved = repo.get('batch1')

    expected = model.Batch('batch1', 'sku1', 100, eta=None)
    expected._allocations = {model.OrderLine('order1', 'sku1', 12)}
    assert retrieved == expected
----
====


Whether or not you painstakingly write tests for every model is a judgement
call.  Once you have one class tested for create/modify/save, you might be
happy to go on and do the others with a minimal roundtrip test, or even nothing
at all, if they all follow a similar pattern.  In our case, the ORM config
that sets up the `._allocations` set is a little complex, so it merited a
specific test.


You end up with something like <<batch_repository>>:


[[batch_repository]]
.A typical repository (repository.py)
====
[source,python]
----
class BatchRepository:

    def __init__(self, session):
        self.session = session

    def add(self, batch):
        self.session.add(batch)

    def get(self, reference):
        return self.session.query(model.Batch).filter_by(reference=reference).one()

    def list(self):
        return self.session.query(model.Batch).all()
----
====


And now our flask endpoint might look something like <<api_endpoint_with_repo>>:

[[api_endpoint_with_repo]]
.Using our repository directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    batches = BatchRepository.list()
    lines = [OrderLine(l['orderid'], l['sku'], l['qty']) for l in lines]
    allocate(lines, batches)
    session.commit()
    return 201
----
====


=== Building a fake repository for tests is now trivial!

Here's one of the biggest benefits of Repository pattern.


[[fake_repository]]
.A simple fake repository subclassing set (repository.py)
====
[role="skip"]
[source,python]
----
class FakeRepository(set):

    def get(self, reference):
        return next(obj for obj in self if obj.reference == reference)
----
====

Because we subclass `set` we get the `.add()` method for free, and
`.get()` is a one-liner.

Using a fake repo in tests is really easy, and we have a simple
abstraction that's easy to use and reason about:

[[fake_repository_example]]
.Example usage of fake repository (test_api.py)
====
[role="skip"]
[source,python]
----
fake_repo = FakeRepository([batch1, batch2, batch3])
----
====


How do we actually instantiate these repositories, fake or real?
What will our flask app actually look like?  Find out in the next
exciting instalment...


.Repository pattern: recap
*****************************************************************
Apply Dependency Inversion to your ORM::
    Our domain model should be free of infrastructure concerns,
    so your ORM should import your model, and not the other way
    around.

Repository pattern is a simple abstraction around permanent storage::
    The repository gives you the illusion of a collection of in-memory
    objects. It makes it very easy to create a `FakeRepository` for
    testing, and it makes it easy to swap fundamental details of you
    infrastructure without disrupting your core application. See
    <<appendix_csvs>> for an example.

*****************************************************************
